{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOBq0+wAMF/gojMzeLhM4Ot",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e0a234238a20442188bffeb50b8a82e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_508da04576294734b60f3fa90d40b2f5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31dda3106cc647fda699a60bf34a320c",
              "IPY_MODEL_7269bb94559540d8a2ad15890118c9a0"
            ]
          }
        },
        "508da04576294734b60f3fa90d40b2f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31dda3106cc647fda699a60bf34a320c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4bbddc49854648ee809cab2744f19f03",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6b91a068a2445da88b086a99123cca1"
          }
        },
        "7269bb94559540d8a2ad15890118c9a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a0c5df4e61074ded90aadad9d9123604",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [01:57&lt;00:00, 23.44s/ url]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ffaa2c46811545579645138631dfcfb7"
          }
        },
        "4bbddc49854648ee809cab2744f19f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6b91a068a2445da88b086a99123cca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0c5df4e61074ded90aadad9d9123604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ffaa2c46811545579645138631dfcfb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b07bff8f8c0242cb9d14c4e9200fe065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c138a58915804d3a82cdab0711e6ee13",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b2f387970f2b453db3beaedc6aaea0a0",
              "IPY_MODEL_10d6cdeac7824a1da0e7ee23a9857162"
            ]
          }
        },
        "c138a58915804d3a82cdab0711e6ee13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2f387970f2b453db3beaedc6aaea0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8cde191a1d694cac973a9ff53c680c6f",
            "_dom_classes": [],
            "description": "Dl Size...: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f715a113aec4444f91d26969ea994d30"
          }
        },
        "10d6cdeac7824a1da0e7ee23a9857162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8fad692c0da84f67b2981b9dc5085798",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 557/? [01:57&lt;00:00,  4.75 MiB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d94643c7f32d4c679260bb0abf305de3"
          }
        },
        "8cde191a1d694cac973a9ff53c680c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f715a113aec4444f91d26969ea994d30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8fad692c0da84f67b2981b9dc5085798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d94643c7f32d4c679260bb0abf305de3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a94f18110c324dc780e714e50491e9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_be9e86e7e0b54aa1a8cceb4a7c44fbd9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d6c60b10cea943e2b0fdba4f546ec849",
              "IPY_MODEL_d8100564205c4989b0cc9512ffdef942"
            ]
          }
        },
        "be9e86e7e0b54aa1a8cceb4a7c44fbd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6c60b10cea943e2b0fdba4f546ec849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_83c6a479d4594efdaa7c8fdf758f86ef",
            "_dom_classes": [],
            "description": "Extraction completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_edb7645bd9cf4ebcb0472ab8413f15ec"
          }
        },
        "d8100564205c4989b0cc9512ffdef942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6dd9062c334a4755ba7b0a1bd86468ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [01:57&lt;00:00, 58.56s/ file]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ecf99f564724d79b28843833d2e9c6b"
          }
        },
        "83c6a479d4594efdaa7c8fdf758f86ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "edb7645bd9cf4ebcb0472ab8413f15ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6dd9062c334a4755ba7b0a1bd86468ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ecf99f564724d79b28843833d2e9c6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "141567d835724105af5415594e9a7f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2293ab6f8444436d826a597626e581f1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e7df796c569f4432b158b7d360cea766",
              "IPY_MODEL_dc0e96d7d05e4ed0ac616431ffc17104"
            ]
          }
        },
        "2293ab6f8444436d826a597626e581f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7df796c569f4432b158b7d360cea766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_845e048e05db4a1ba2fbe08d84aefa40",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15172d9909fd47dc98f1666eb3ab3102"
          }
        },
        "dc0e96d7d05e4ed0ac616431ffc17104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_058be0a299de4e408294b8551c55bc63",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 222894/0 [15:10&lt;00:00, 231.40 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ecd6166ed4b41b9b09da5d04d26ada4"
          }
        },
        "845e048e05db4a1ba2fbe08d84aefa40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15172d9909fd47dc98f1666eb3ab3102": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "058be0a299de4e408294b8551c55bc63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ecd6166ed4b41b9b09da5d04d26ada4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44757a3a7afe4e4eb95e95f11e94baed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fee20f84e6204e7bad616f22de2b85ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_673b5f7827d7437f92e1f3240161aa5a",
              "IPY_MODEL_9170fc91ba304ad8b6a4c2d2ccb31355"
            ]
          }
        },
        "fee20f84e6204e7bad616f22de2b85ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "673b5f7827d7437f92e1f3240161aa5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e561f9e07090434cb77090aeddc4789a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 344259,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 344259,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de0381976d7c4fc68b06665cbae12834"
          }
        },
        "9170fc91ba304ad8b6a4c2d2ccb31355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6d81c8e6bbaa47139a9161791c49e526",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 344k/344k [00:01&lt;00:00, 303kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db5a8e04fa0949de9cfc76eb7494f9ca"
          }
        },
        "e561f9e07090434cb77090aeddc4789a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de0381976d7c4fc68b06665cbae12834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d81c8e6bbaa47139a9161791c49e526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db5a8e04fa0949de9cfc76eb7494f9ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6fb86e6f6914670968ad70d09ab5852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bd03d7a79e02416ebcdb5f6193414fe3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b656b044f5964b18a69be602cf391abf",
              "IPY_MODEL_3bb580a2181641c48ca8a14da6e7c2a0"
            ]
          }
        },
        "bd03d7a79e02416ebcdb5f6193414fe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b656b044f5964b18a69be602cf391abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ceff003d619437d8ecae1bf080db110",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 684,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 684,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c807b711d5e84e2fb60db9716f57a004"
          }
        },
        "3bb580a2181641c48ca8a14da6e7c2a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c478a8fd1214967a49ba63b7a5f5c2d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 684/684 [00:00&lt;00:00, 802B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a15c90485f04cdab63dcd9704bc68d7"
          }
        },
        "4ceff003d619437d8ecae1bf080db110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c807b711d5e84e2fb60db9716f57a004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c478a8fd1214967a49ba63b7a5f5c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a15c90485f04cdab63dcd9704bc68d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc2d8144b76b471a824dddd49b6c5889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_51dca6c50af5412994758f1c854a78de",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2448a43b9a3645cebcabe6a5c21b0d6f",
              "IPY_MODEL_0c511bccc20b4815a1ff1a54d40f94da"
            ]
          }
        },
        "51dca6c50af5412994758f1c854a78de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2448a43b9a3645cebcabe6a5c21b0d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_508cd332718045e290ac9a43cf950af3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 53325832,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 53325832,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42119f7a708b411b93a877db42feae49"
          }
        },
        "0c511bccc20b4815a1ff1a54d40f94da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5dad0c302f7d4533ada1482eebc97809",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 53.3M/53.3M [00:52&lt;00:00, 1.02MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73e88e9c09f44e86a9ae023ec7f6ed21"
          }
        },
        "508cd332718045e290ac9a43cf950af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42119f7a708b411b93a877db42feae49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5dad0c302f7d4533ada1482eebc97809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73e88e9c09f44e86a9ae023ec7f6ed21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "900992c9731b494a836b090acd817255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4a609fde633448e4abedf96a3ca46514",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aee229bbb2cb4014a2aaaa7de42ecadc",
              "IPY_MODEL_804ff19fd0c34b33a64d3db138eee97b"
            ]
          }
        },
        "4a609fde633448e4abedf96a3ca46514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aee229bbb2cb4014a2aaaa7de42ecadc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_628451d485bb41b687e0388a3a0733d9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 760289,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 760289,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04f37ec1ff4a455b84732cde635a7a32"
          }
        },
        "804ff19fd0c34b33a64d3db138eee97b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1210ff77115442c8adea202c2384ad7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 760k/760k [00:00&lt;00:00, 1.09MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_daa84cb7428547dda7903cbeb1648392"
          }
        },
        "628451d485bb41b687e0388a3a0733d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04f37ec1ff4a455b84732cde635a7a32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1210ff77115442c8adea202c2384ad7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "daa84cb7428547dda7903cbeb1648392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20e74878ee6d4169838f5ebcd9bf9105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2b8569172ab848749ef1d1fbaaf12666",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4922360857c941f8ba39fa6b714f368d",
              "IPY_MODEL_b38b917be9b24e0088cc29f43318e8e5"
            ]
          }
        },
        "2b8569172ab848749ef1d1fbaaf12666": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4922360857c941f8ba39fa6b714f368d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_34b650cda7e6401281b3d38a515a9bbc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1312669,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1312669,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c0903beadef4ee9980a15bc0fac1125"
          }
        },
        "b38b917be9b24e0088cc29f43318e8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ff724f00db740828f6f3167b7586b6b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.31M/1.31M [00:22&lt;00:00, 57.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d558b31da7c84edc86e1b08c0f9c44dd"
          }
        },
        "34b650cda7e6401281b3d38a515a9bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c0903beadef4ee9980a15bc0fac1125": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ff724f00db740828f6f3167b7586b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d558b31da7c84edc86e1b08c0f9c44dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "733866c92eec4255b38e995e9b7ba0b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_13052ef80a744def9c3537a2ac0750c3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5d3816317c6843efbd58e22c6ffea1e2",
              "IPY_MODEL_b7f8684692d740c2a684aba285114e1b"
            ]
          }
        },
        "13052ef80a744def9c3537a2ac0750c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d3816317c6843efbd58e22c6ffea1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_89cf8cf5c0554bb886a5749336ca8ee7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 685,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 685,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc2ea1c1d9a448cd84cd1af0c731e4fe"
          }
        },
        "b7f8684692d740c2a684aba285114e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c66d419b769649b18f80dba829755316",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 685/685 [00:00&lt;00:00, 1.28kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa3bc3bdaf5d48d5b678ca4cf01930cb"
          }
        },
        "89cf8cf5c0554bb886a5749336ca8ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc2ea1c1d9a448cd84cd1af0c731e4fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c66d419b769649b18f80dba829755316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa3bc3bdaf5d48d5b678ca4cf01930cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e942b3ef56f449299c8d22c98b5443d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c0282cbb9c9c42ec910ecfe70e6bb49c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_978efca384e942b4aec18babdf2e9b6a",
              "IPY_MODEL_6502ffd64d1940509266fa7d5890b669"
            ]
          }
        },
        "c0282cbb9c9c42ec910ecfe70e6bb49c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "978efca384e942b4aec18babdf2e9b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_86da887a18b44fa1a450129f2c8986d7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 236197176,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 236197176,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_132e520423e94ef39e88cb0b872a006e"
          }
        },
        "6502ffd64d1940509266fa7d5890b669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3a5049dee38641f08f01c4c58e4a09c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 236M/236M [00:21&lt;00:00, 10.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f07e69a62694d099a85e21b39328ecf"
          }
        },
        "86da887a18b44fa1a450129f2c8986d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "132e520423e94ef39e88cb0b872a006e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a5049dee38641f08f01c4c58e4a09c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f07e69a62694d099a85e21b39328ecf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f95af5dd0ad2453c98844469c6c0369d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_542aa6f5c3e94009be307fd9cc7e6408",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fe0d8c696f9644d598eebfef52978517",
              "IPY_MODEL_ed9acc2394a14d05b009c6fe46c8ce3c"
            ]
          }
        },
        "542aa6f5c3e94009be307fd9cc7e6408": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe0d8c696f9644d598eebfef52978517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fba25d63e9614f9691577e548467074b",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1710,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1710,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46119ae8b33d402e9e14ef2983559f06"
          }
        },
        "ed9acc2394a14d05b009c6fe46c8ce3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f7cad090fe6541429cca37a3fadf7244",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.50k/? [00:02&lt;00:00, 1.98kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04c12ccfffd3400b8fbf27416086fd7a"
          }
        },
        "fba25d63e9614f9691577e548467074b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46119ae8b33d402e9e14ef2983559f06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7cad090fe6541429cca37a3fadf7244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04c12ccfffd3400b8fbf27416086fd7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abe036311be64734a8a4ff3520ed1854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_307485b366e54d0db305e87bb054b875",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8f8d6354c09e4e3fb10cef30eefcfe95",
              "IPY_MODEL_d6264dc5cacc4b7e9d2da02b794fca00"
            ]
          }
        },
        "307485b366e54d0db305e87bb054b875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f8d6354c09e4e3fb10cef30eefcfe95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_934a430476b04c5f90d52098b79b85ac",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 962,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 962,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eccf84dec1d54300b1f4aa3c0b0283b9"
          }
        },
        "d6264dc5cacc4b7e9d2da02b794fca00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_11788a079e1a4e659eba67cad37f9db7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.24k/? [00:00&lt;00:00, 44.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af5a7aa73df44e7da5ae5cb6600bb7a5"
          }
        },
        "934a430476b04c5f90d52098b79b85ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eccf84dec1d54300b1f4aa3c0b0283b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11788a079e1a4e659eba67cad37f9db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af5a7aa73df44e7da5ae5cb6600bb7a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fcb63762f109495eaec5e986ed8d47ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ae03d406f7d24d1eafc0f102ac36f620",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a726d0ea30a54a0b8195512090d8f2fc",
              "IPY_MODEL_3960871bf6c44e1992c4546f600000a2"
            ]
          }
        },
        "ae03d406f7d24d1eafc0f102ac36f620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a726d0ea30a54a0b8195512090d8f2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ceb1e77743594ebeafac45a38f7211b1",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7568316,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7568316,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1325cc98dec64864b369ffe20967c5a3"
          }
        },
        "3960871bf6c44e1992c4546f600000a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e9495c01bbf64fe093166943b9d2c946",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 38.5M/? [00:00&lt;00:00, 60.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30c8b8b8d0da421f952a0e02f86808da"
          }
        },
        "ceb1e77743594ebeafac45a38f7211b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1325cc98dec64864b369ffe20967c5a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9495c01bbf64fe093166943b9d2c946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30c8b8b8d0da421f952a0e02f86808da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8aca210eb4db4d1096ffe5b182dfbd75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b96072972cd74d1da530ce7a51f7cd44",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ec292c4d93b24cc78698ab42e3efc529",
              "IPY_MODEL_23a84e0e5c3441b0b870b1b5834c7603"
            ]
          }
        },
        "b96072972cd74d1da530ce7a51f7cd44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec292c4d93b24cc78698ab42e3efc529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_800baa665d7141c2a8a87e6f208205da",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 770480,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 770480,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e304dbe27844b1682f74db353ca6be7"
          }
        },
        "23a84e0e5c3441b0b870b1b5834c7603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_60aca6b057e641d9a0784417fbc3b50f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3.88M/? [00:00&lt;00:00, 14.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_293a0adf173b40dcbf3aca1166da112c"
          }
        },
        "800baa665d7141c2a8a87e6f208205da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e304dbe27844b1682f74db353ca6be7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60aca6b057e641d9a0784417fbc3b50f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "293a0adf173b40dcbf3aca1166da112c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b72efa4d6994de4a3c939d2a5696833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_712dd6241561459cad7fca9a391cae16",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2a9d5509cec043aa8265f9126d538226",
              "IPY_MODEL_f80926be439d4d9c8acf5571a04d5f40"
            ]
          }
        },
        "712dd6241561459cad7fca9a391cae16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a9d5509cec043aa8265f9126d538226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_43c0ae258df441d087a1af3d7cb48833",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d6b3726ae2544f0bd6a57bf25574ae1"
          }
        },
        "f80926be439d4d9c8acf5571a04d5f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0dc553e839bd41409b47bc5205a8f0a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 60407/0 [00:05&lt;00:00, 3156.78 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9cae9a8928d40afbe94174c655ac834"
          }
        },
        "43c0ae258df441d087a1af3d7cb48833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d6b3726ae2544f0bd6a57bf25574ae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0dc553e839bd41409b47bc5205a8f0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9cae9a8928d40afbe94174c655ac834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49180f796c004ca787dc81d8ef9acd35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7c3bfdd325894a34b9b2f16083e7ba47",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_29d2a17be6e14b45b5ce15bbe7b53cc3",
              "IPY_MODEL_3582486f19584d139856c652ece67b7c"
            ]
          }
        },
        "7c3bfdd325894a34b9b2f16083e7ba47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29d2a17be6e14b45b5ce15bbe7b53cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e0a040fb522b45489f5a86028d462c85",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95fa74684d87493f85682675c818f882"
          }
        },
        "3582486f19584d139856c652ece67b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3eea9c3f59e144f593935c4c745cbcda",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5774/0 [00:00&lt;00:00, 7246.50 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_194e4e272e0443c4ba2c4189d8d6baad"
          }
        },
        "e0a040fb522b45489f5a86028d462c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95fa74684d87493f85682675c818f882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3eea9c3f59e144f593935c4c745cbcda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "194e4e272e0443c4ba2c4189d8d6baad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolmani38/QA/blob/main/Train_korQuAD1.0_0516.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21tlIhtCjJia"
      },
      "source": [
        "# 한국어 Albert Tokenizer 학습!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc1weyK_jPwQ",
        "outputId": "926ed23a-5e68-46cb-fba5-d2453c6bac23"
      },
      "source": [
        "\n",
        "if True:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5DRavVNRey3"
      },
      "source": [
        "## 참조\n",
        "\n",
        "https://colab.research.google.com/github/parmarsuraj99/suraj-parmar/blob/master/_notebooks/2020-05-02-SanskritALBERT.ipynb#scrollTo=VNAOMXjpMHZD\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "038IYm33Muol"
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import glob\n",
        "import torch\n",
        "import pickle\n",
        "import joblib\n",
        "from tqdm.auto import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVCIQF4UMmyF",
        "outputId": "7a63415d-00e1-4414-e758-35f802d7d3d6"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers\n",
        "!pip install transformers/.\n",
        "!pip install sentencepiece==0.1.95\n",
        "!pip install datasets==1.6.2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 72723, done.\u001b[K\n",
            "remote: Counting objects: 100% (761/761), done.\u001b[K\n",
            "remote: Compressing objects: 100% (425/425), done.\u001b[K\n",
            "remote: Total 72723 (delta 440), reused 516 (delta 292), pack-reused 71962\u001b[K\n",
            "Receiving objects: 100% (72723/72723), 56.22 MiB | 16.86 MiB/s, done.\n",
            "Resolving deltas: 100% (51559/51559), done.\n",
            "Processing ./transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (4.0.1)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 12.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 51.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.7.0.dev0) (20.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.7.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.7.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.7.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0.dev0) (8.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.7.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.7.0.dev0) (2.4.7)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.7.0.dev0-cp37-none-any.whl size=2261775 sha256=d8a07ed59a7a03f12f1d3092b5914074badd3c030152158eeb5680f93ec37296\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m0avywhs/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "Successfully built transformers\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.7.0.dev0\n",
            "Collecting sentencepiece==0.1.95\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 7.4MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n",
            "Collecting datasets==1.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/1a/b9f9b3bfef624686ae81c070f0a6bb635047b17cdb3698c7ad01281e6f9a/datasets-1.6.2-py3-none-any.whl (221kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2) (20.9)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2) (0.70.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2) (1.1.5)\n",
            "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2) (3.0.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2) (4.41.1)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2) (0.0.8)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2) (0.3.3)\n",
            "Collecting fsspec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/52/816d1a3a599176057bf29dfacb1f8fadb61d35fbd96cb1bab4aaa7df83c0/fsspec-2021.5.0-py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 68.5MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 73.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.2) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets==1.6.2) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.6.2) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.6.2) (2.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.6.2) (3.0.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets==1.6.2) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets==1.6.2) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.6.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.6.2) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.6.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.6.2) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.6.2) (1.15.0)\n",
            "Installing collected packages: fsspec, xxhash, datasets\n",
            "Successfully installed datasets-1.6.2 fsspec-2021.5.0 xxhash-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQt6ukg-M5p9"
      },
      "source": [
        "## mecab 설치 참조\n",
        "\n",
        "https://somjang.tistory.com/entry/Google-Colab%EC%97%90%EC%84%9C-Mecab-koMecab-ko-dic-%EC%89%BD%EA%B2%8C-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E1YDPFdMslI",
        "outputId": "02b58627-275a-4a5c-8979-f06ff6627975"
      },
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 91 (delta 43), reused 22 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (91/91), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1XdrdGGM9ky",
        "outputId": "a62569f9-26fb-40a5-c7de-af343053b72d"
      },
      "source": [
        "!bash ./Mecab-ko-for-Google-Colab/install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing konlpy.....\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a5/9781e2ef4ca92d09912c4794642c1653aea7607f473e156cf4d423a881a1/JPype1-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 38.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: colorama, JPype1, beautifulsoup4, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2021-05-16 00:27:56--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::6b17:d1f5, 2406:da00:ff00::22cd:e0db, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=67OlFPehmTqro5oAkWE3QxK%2FEUs%3D&Expires=1621126677&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-05-16 00:27:57--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=67OlFPehmTqro5oAkWE3QxK%2FEUs%3D&Expires=1621126677&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.14.12\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.14.12|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  2.76MB/s    in 0.5s    \n",
            "\n",
            "2021-05-16 00:27:58 (2.76 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2021-05-16 00:29:28--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22cd:e0db, 2406:da00:ff00::6b17:d1f5, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=AFp1DDrdBcn9tGABJKqq%2BkVxBHM%3D&Expires=1621126768&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-05-16 00:29:28--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=AFp1DDrdBcn9tGABJKqq%2BkVxBHM%3D&Expires=1621126768&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.0.164\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.0.164|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  24.3MB/s    in 2.0s    \n",
            "\n",
            "2021-05-16 00:29:31 (24.3 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecJdu9LKxh2z"
      },
      "source": [
        "# 한국어 Tokenizer 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaP5MmCejnq_"
      },
      "source": [
        "## dataset 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqRjnbbJlpBl"
      },
      "source": [
        "### 네이버 뉴스.... 영화 평가 댓글... 에서 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUJMmmyZmpqX",
        "outputId": "994eb67e-8960-47ed-c6d1-85097cf422ec"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea31IIPRm2cy"
      },
      "source": [
        "\n",
        "# 간단한 전처리\n",
        "def clean_text(txt):\n",
        "    txt = txt.replace('\\n',' ')\n",
        "    txt = txt.replace('\\r',' ')    \n",
        "    txt = txt.replace('=','')\n",
        "    txt = txt.replace('\\\"','')   \n",
        "    txt = txt.replace('\\'','')\n",
        "    #txt = txt.replace(',','')\n",
        "    txt = txt.replace('..','')\n",
        "    txt = txt.replace('...','')\n",
        "    #txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('.','. ')\n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')           \n",
        "    txt = txt.replace('  ',' ')\n",
        "    txt = txt.replace('  ',' ')    \n",
        "    txt = txt.replace('  ',' ')   \n",
        "    txt = txt.replace('  ',' ')             \n",
        "    return txt.strip()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RijcRl1ukG3Z",
        "outputId": "0967639c-2c8d-4d60-ba25-878b7e67afa6"
      },
      "source": [
        "%%time\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/summary/korean_news_corpus.csv')\n",
        "# 검사...\n",
        "pattens = [\"[34569][0-9]{3}[\\;.\\;-\\; ][0-9]{4}[\\;.\\;-\\; ][0-9]{4}[\\;.\\;-\\; ][0-9]{4}\",\n",
        "           \"[0-9]{2,3}[\\:\\s\\;.\\;,\\;-;)][0-9]{3,4}[\\:\\s\\;.\\;,\\;-][0-9]{4}\",\n",
        "           \"[0-9]{1}[0-9]{1}[\\W]?[0-1]{1}[0-9]{1}[\\W]?[0-3]{1}[\\W]?[0-9]{1}[\\W]?[1-4]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}[\\W]?[0-9]{1}\",\n",
        "           \"[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{3}[\\:\\s\\;.\\;,\\;-]([0-9]{5,6}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9]{5}|[0-9]{2,3}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{7}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{4,6}[\\:\\s\\;.\\;,\\;-][0-9]|[0-9]{5}[\\:\\s\\;.\\;,\\;-][0-9]{3}[\\:\\s\\;.\\;,\\;-][0-9]{2}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{5}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{4}[\\:\\s\\;.\\;,\\;-][0-9]{4}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{3}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{7})|[0-9]{4}[\\:\\s\\;.\\;,\\;-]([0-9]{3}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9])|[0-9]{5}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{6}|[0-9]{6}[\\:\\s\\;.\\;,\\;-][0-9]{2}[\\:\\s\\;.\\;,\\;-][0-9]{5,6}\"\n",
        "           ]\n",
        "\n",
        "filters = []\n",
        "for p in pattens:\n",
        "    filters.append(re.compile(p))\n",
        "\n",
        "sentences = []\n",
        "df = df.dropna(axis=0)\n",
        "cnt = df['contents'].count()\n",
        "print('Total row count:',cnt)\n",
        "i=0\n",
        "for raw_text in df['contents']:\n",
        "    i=i+1\n",
        "    try:\n",
        "        if i%100 == 0:\n",
        "            percent = (\"{0:.2f}\").format(100 * (i / float(cnt)))\n",
        "            print(f'\\r {percent}% {i}/{str(cnt)}', end=\"\", flush=True)\n",
        "\n",
        "        docs = nltk.sent_tokenize(clean_text(raw_text))\n",
        "        for txt in docs:\n",
        "            if txt.find('▶') > -1 or txt.find('@') > -1 or txt.find('ⓒ') > -1: \n",
        "                pass\n",
        "            else:\n",
        "                txt = txt.strip()\n",
        "                if any(chr.isdigit() for chr in txt) :\n",
        "                    pass\n",
        "                else:\n",
        "                    sentences.append(txt)\n",
        "    except KeyboardInterrupt as ki:\n",
        "        raise ki        \n",
        "    except:\n",
        "        pass #print(\"Unexpected error:\", sys.exc_info()[0])\n",
        "\n",
        "print('')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total row count: 140536\n",
            " 99.97% 140500/140536\n",
            "CPU times: user 3min 19s, sys: 4.44 s, total: 3min 24s\n",
            "Wall time: 3min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U-syo92kQis",
        "outputId": "f980d0f8-66cd-4884-9a28-d066da55a4f5"
      },
      "source": [
        "len(sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2967202"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcekjFG6nvX9",
        "outputId": "a8a969de-2175-4e42-f455-e77b56349506"
      },
      "source": [
        "sentences[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['연합뉴스 문재인 대통령이 변창흠 국토교통부 장관의 사의 표명을 사실상 수용했다.',\n",
              " '문 대통령은 변 장관의 사의 표명에 책임지는 모습을 보일 수밖에 없다고 밝혔다.',\n",
              " '이는 문 대통령이 사실상 변 장관의 사의를 수용한 것으로 해석된다.',\n",
              " '이에 앞서 변창흠 국토교통부 장관은 LH 땅 투기 의혹 사건과 관련한 책임론에 대해 “자리에 연연하지 않는다”면서 “(청와대의) 결정에 따르겠다”고 말했다.',\n",
              " '변 장관은 이날 국회 국토교통위원회 전체회의에 참석해 “LH 사태로 국민들이 걱정하는 부분을 해소할 수 있게 최대한 대안을 만들고 LH가 근본적으로 다시 태어날 수 있도록 책임지고 추진하겠다”고 언급하고 “그 역할이 충분하다고 평가되지 못했을 때 언제든지 자리에 연연하지 않고 결정에 따르겠다”고 말했다.',\n",
              " 'kr ) 무단 전재 및 재배포 금지',\n",
              " 'kr ) 무단 전재 및 재배포 금지',\n",
              " 'kr ) 무단 전재 및 재배포 금지',\n",
              " '인재 양성·소외 계층 지원 등 계획 “부친 질병·가난 악순환 끊기 원해 국내 최고 넘어 세계적 병원 되길 정몽구 현대차그룹 명예회장.',\n",
              " '그는 “질병과 가난이 악순환되는 고리를 끊기 위해 아산재단과 서울아산병원을 설립했던 아버님의 뜻을 이어 우리 사회의 어려운 이웃을 돕는 데 보탬이 되기를 바란다”고 기부 취지를 밝혔다.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGheAmmIkVQ4",
        "outputId": "cd480125-d385-433e-8822-7cb5d2398f61"
      },
      "source": [
        "%%time\n",
        "\n",
        "import re\n",
        "import sys\n",
        "import io\n",
        "\n",
        "#텍스트 정제(전처리)\n",
        "def cleanText(readData):\n",
        "    #텍스트에 포함되어 있는 특수 문자 제거\n",
        "    text = re.sub('[-=+#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》◆◇●🎧○▲\\t―△━▷]', '', readData)\n",
        "    return text\n",
        "\n",
        "c_sentences = []\n",
        "for sentence in sentences:\n",
        "    s = cleanText(sentence)\n",
        "    c = len(s.split())\n",
        "    if c >= 3 and c < 10 and s.find('재배포') < 0 and s.find('기자') < 0  and s.find('유투브') < 0 and s.find('www') < 0 and s.find('com') < 0 and s.find('접속하기') < 0 and s.find('http') < 0 and s.find('뉴스') < 0 and s.find('일보') < 0 :\n",
        "        if s.endswith(('다','요')):\n",
        "            c_sentences.append(s.strip())    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 12.8 s, sys: 194 ms, total: 13 s\n",
            "Wall time: 13 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb6oBQFrkV_3",
        "outputId": "73faa22b-c98a-4795-b050-1ced40a7238e"
      },
      "source": [
        "len(c_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "867766"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChgB1u3fmQzL"
      },
      "source": [
        "# 한국어 영화 리뷰를 Load.\n",
        "ds = pd.read_csv(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\",sep='\\t')\n",
        "for row in ds.iterrows():\n",
        "    doc_id = row[1][0]\n",
        "    doc_cont = str(row[1][1])\n",
        "    c_sentences.append(doc_cont)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8W3HKirnUG1",
        "outputId": "61ba768e-5664-4127-cf24-72129b4f5fab"
      },
      "source": [
        "len(c_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1017766"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDANhUJ9qDel"
      },
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(c_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugNi7PH5qtw2"
      },
      "source": [
        "### 한국어... 교착어 처리..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMRu1dDHqre-",
        "outputId": "ca4c1a6e-82f9-4f82-e14d-cf082d44c55a"
      },
      "source": [
        "%%time\n",
        "# mecab for window는 아래 코드 사용\n",
        "from konlpy.tag import Mecab  # install mecab for window: https://hong-yp-ml-records.tistory.com/91\n",
        "mecab_tokenizer = Mecab().morphs\n",
        "print('mecab check :', mecab_tokenizer('어릴때보고 지금다시봐도 재밌어요ㅋㅋ'))\n",
        "\n",
        "ko_sentences = []\n",
        "\n",
        "for sentence in c_sentences:\n",
        "    # 문장단위 mecab 적용\n",
        "    morph_sentence= mecab_tokenizer(sentence)\n",
        "    # 문장단위 저장\n",
        "    ko_sentences.append( (' '.join(morph_sentence)).strip())\n",
        "        \n",
        "num_word_list = [len(sentence.split()) for sentence in ko_sentences]\n",
        "print('\\n힌국어 코퍼스 평균/총 단어 갯수 : %.1f / %d' % (sum(num_word_list)/len(num_word_list), sum(num_word_list)))       "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mecab check : ['어릴', '때', '보', '고', '지금', '다시', '봐도', '재밌', '어요', 'ㅋㅋ']\n",
            "\n",
            "힌국어 코퍼스 평균/총 단어 갯수 : 13.7 / 13929565\n",
            "CPU times: user 1min 23s, sys: 849 ms, total: 1min 24s\n",
            "Wall time: 1min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2ZFt4Xrnpak",
        "outputId": "0995fdf5-c176-43c9-8696-3766967f0e8b"
      },
      "source": [
        "%%time\n",
        "# subword 학습을 위해 문장만 따로 저장\n",
        "with open('/content/drive/MyDrive/Tokenizer_train/data/train_tokenizer.txt', 'w', encoding='utf-8') as f:\n",
        "    for line in ko_sentences:\n",
        "        f.write(line+'\\n')\n",
        "\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 575 ms, sys: 115 ms, total: 691 ms\n",
            "Wall time: 2.14 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sZ4yn-toGXw"
      },
      "source": [
        "### CNN/Daily main Dataset에서 영어... 문장 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647,
          "referenced_widgets": [
            "e0a234238a20442188bffeb50b8a82e0",
            "508da04576294734b60f3fa90d40b2f5",
            "31dda3106cc647fda699a60bf34a320c",
            "7269bb94559540d8a2ad15890118c9a0",
            "4bbddc49854648ee809cab2744f19f03",
            "a6b91a068a2445da88b086a99123cca1",
            "a0c5df4e61074ded90aadad9d9123604",
            "ffaa2c46811545579645138631dfcfb7",
            "b07bff8f8c0242cb9d14c4e9200fe065",
            "c138a58915804d3a82cdab0711e6ee13",
            "b2f387970f2b453db3beaedc6aaea0a0",
            "10d6cdeac7824a1da0e7ee23a9857162",
            "8cde191a1d694cac973a9ff53c680c6f",
            "f715a113aec4444f91d26969ea994d30",
            "8fad692c0da84f67b2981b9dc5085798",
            "d94643c7f32d4c679260bb0abf305de3",
            "a94f18110c324dc780e714e50491e9fa",
            "be9e86e7e0b54aa1a8cceb4a7c44fbd9",
            "d6c60b10cea943e2b0fdba4f546ec849",
            "d8100564205c4989b0cc9512ffdef942",
            "83c6a479d4594efdaa7c8fdf758f86ef",
            "edb7645bd9cf4ebcb0472ab8413f15ec",
            "6dd9062c334a4755ba7b0a1bd86468ca",
            "0ecf99f564724d79b28843833d2e9c6b",
            "141567d835724105af5415594e9a7f9a",
            "2293ab6f8444436d826a597626e581f1",
            "e7df796c569f4432b158b7d360cea766",
            "dc0e96d7d05e4ed0ac616431ffc17104",
            "845e048e05db4a1ba2fbe08d84aefa40",
            "15172d9909fd47dc98f1666eb3ab3102",
            "058be0a299de4e408294b8551c55bc63",
            "6ecd6166ed4b41b9b09da5d04d26ada4"
          ]
        },
        "id": "gpv2vn9Bom28",
        "outputId": "c0512baf-6051-4174-90f4-ec6cbecbca8a"
      },
      "source": [
        "\n",
        "import tensorflow_datasets as tfds\n",
        "train_data, test_data = tfds.load(name=\"cnn_dailymail\",split=(tfds.Split.TRAIN,tfds.Split.TEST),with_info=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset cnn_dailymail/plain_text/3.0.0 (download: 558.32 MiB, generated: 1.27 GiB, total: 1.82 GiB) to /root/tensorflow_datasets/cnn_dailymail/plain_text/3.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0a234238a20442188bffeb50b8a82e0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b07bff8f8c0242cb9d14c4e9200fe065",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a94f18110c324dc780e714e50491e9fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Extraction completed...', max=1.0, styl…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "141567d835724105af5415594e9a7f9a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-7ea54526221a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cnn_dailymail\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwith_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    342\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mas_dataset_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, download_dir, download_config)\u001b[0m\n\u001b[1;32m    385\u001b[0m           self._download_and_prepare(\n\u001b[1;32m    386\u001b[0m               \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m               download_config=download_config)\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m           \u001b[0;31m# NOTE: If modifying the lines below to put additional information in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     super(GeneratorBasedBuilder, self)._download_and_prepare(\n\u001b[1;32m   1023\u001b[0m         \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0mmax_examples_per_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_examples_per_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m       \u001b[0;31m# Prepare split will record examples associated to the split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m     \u001b[0;31m# Update the info object with the splits.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_prepare_split\u001b[0;34m(self, split_generator, max_examples_per_split)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                      hash_salt=split_generator.name)\n\u001b[1;32m   1038\u001b[0m     for key, record in utils.tqdm(generator, unit=\" examples\",\n\u001b[0;32m-> 1039\u001b[0;31m                                   total=split_info.num_examples, leave=False):\n\u001b[0m\u001b[1;32m   1040\u001b[0m       \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/summarization/cnn_dailymail.py\u001b[0m in \u001b[0;36m_generate_examples\u001b[0;34m(self, files)\u001b[0m\n\u001b[1;32m    306\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_generate_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m       \u001b[0marticle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhighlights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_art_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhighlights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/summarization/cnn_dailymail.py\u001b[0m in \u001b[0;36m_get_art_abs\u001b[0;34m(story_file, tfds_version)\u001b[0m\n\u001b[1;32m    187\u001b[0m   \u001b[0;31m#     make_datafiles.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m   \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_text_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m   \u001b[0;31m# The github code lowercase the text and we removed it in 3.0.0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/summarization/cnn_dailymail.py\u001b[0m in \u001b[0;36m_read_text_file\u001b[0;34m(text_file)\u001b[0m\n\u001b[1;32m    177\u001b[0m   \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m       \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;34mr\"\"\"Reads the next line, keeping \\n. At EOF, returns ''.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc7bauWlov2n"
      },
      "source": [
        "%%time\n",
        "en_sentences = []\n",
        "iterator = iter(test_data[0])\n",
        "for data in iterator:\n",
        "    article = nltk.sent_tokenize(data['article'].numpy().decode('UTF-8'))\n",
        "    for sent in article:    \n",
        "        en_sentences.append(sent)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VhwqYk_o32m"
      },
      "source": [
        "num_word_list = [len(sentence.split()) for sentence in en_sentences]\n",
        "print('\\n영어 코퍼스 평균/총 단어 갯수 : %.1f / %d' % (sum(num_word_list)/len(num_word_list), sum(num_word_list)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V3QEInEkhEl",
        "outputId": "899d9a85-fd37-466d-b87c-2999f9f7d720"
      },
      "source": [
        "%%time\n",
        "# subword 학습을 위해 문장만 따로 저장\n",
        "with open('/content/drive/MyDrive/Tokenizer_train/data/train_tokenizer.txt', 'w', encoding='utf-8') as f:\n",
        "    for line in ko_sentences:\n",
        "        f.write(line+'\\n')\n",
        "\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 288 ms, sys: 40.3 ms, total: 328 ms\n",
            "Wall time: 1.35 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNXWYH5FRyu1"
      },
      "source": [
        "# 여기서부터 다시"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-ircJrdZKh6",
        "outputId": "f974e1d8-fe7d-474e-de39-cd5334904669"
      },
      "source": [
        "%%time\n",
        "import sentencepiece as spm\n",
        "import os\n",
        "# spm_train --input=data/train_tokenizer.txt  --model_prefix=sentencepiece/sp --vocab_size=32000 character_coverage=1.0 --model_type=\"unigram\"\n",
        "\n",
        "input_file = '/content/drive/MyDrive/Tokenizer_train/data/train_tokenizer.txt'\n",
        "vocab_size = 30015\n",
        "\n",
        "sp_model_root='/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model'\n",
        "if not os.path.isdir(sp_model_root):\n",
        "    os.mkdir(sp_model_root)\n",
        "sp_model_name = 'spiece'\n",
        "sp_model_path = os.path.join(sp_model_root, sp_model_name)\n",
        "model_type = 'unigram'  # 학습할 모델 선택, unigram이 더 성능이 좋음'bpe'\n",
        "character_coverage  = 1.0  # 전체를 cover 하기 위해, default=0.9995\n",
        "user_defined_symbols = '[PAD],[UNK],[CLS],[SEP],[MASK],[BOS],[EOS],[UNK0],[UNK1],[UNK2],[UNK3],[UNK4],[UNK5],[UNK6],[UNK7],[UNK8],[UNK9],[unused0],[unused1],[unused2],[unused3],[unused4],[unused5],[unused6],[unused7],[unused8],[unused9],[unused10],[unused11],[unused12],[unused13],[unused14],[unused15],[unused16],[unused17],[unused18],[unused19],[unused20],[unused21],[unused22],[unused23],[unused24],[unused25],[unused26],[unused27],[unused28],[unused29],[unused30],[unused31],[unused32],[unused33],[unused34],[unused35],[unused36],[unused37],[unused38],[unused39],[unused40],[unused41],[unused42],[unused43],[unused44],[unused45],[unused46],[unused47],[unused48],[unused49],[unused50],[unused51],[unused52],[unused53],[unused54],[unused55],[unused56],[unused57],[unused58],[unused59],[unused60],[unused61],[unused62],[unused63],[unused64],[unused65],[unused66],[unused67],[unused68],[unused69],[unused70],[unused71],[unused72],[unused73],[unused74],[unused75],[unused76],[unused77],[unused78],[unused79],[unused80],[unused81],[unused82],[unused83],[unused84],[unused85],[unused86],[unused87],[unused88],[unused89],[unused90],[unused91],[unused92],[unused93],[unused94],[unused95],[unused96],[unused97],[unused98],[unused99]'\n",
        "\n",
        "input_argument = '--input=%s --model_prefix=%s --vocab_size=%s --user_defined_symbols=%s --model_type=%s --character_coverage=%s'\n",
        "cmd = input_argument%(input_file, sp_model_path, vocab_size,user_defined_symbols, model_type, character_coverage)\n",
        "\n",
        "spm.SentencePieceTrainer.Train(cmd)\n",
        "print('train done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train done\n",
            "CPU times: user 33.2 s, sys: 667 ms, total: 33.9 s\n",
            "Wall time: 28.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55T0J0MDFtrm",
        "outputId": "99638ebd-6ef5-4187-e2c4-e55dda183044"
      },
      "source": [
        "## 1) define special tokens\n",
        "user_defined_symbols = ['[BOS]','[EOS]','[UNK0]','[UNK1]','[UNK2]','[UNK3]','[UNK4]','[UNK5]','[UNK6]','[UNK7]','[UNK8]','[UNK9]']\n",
        "unused_token_num = 200\n",
        "unused_list = ['[unused{}]'.format(n) for n in range(unused_token_num)]\n",
        "user_defined_symbols = user_defined_symbols + unused_list\n",
        "\n",
        "print(user_defined_symbols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[BOS]', '[EOS]', '[UNK0]', '[UNK1]', '[UNK2]', '[UNK3]', '[UNK4]', '[UNK5]', '[UNK6]', '[UNK7]', '[UNK8]', '[UNK9]', '[unused0]', '[unused1]', '[unused2]', '[unused3]', '[unused4]', '[unused5]', '[unused6]', '[unused7]', '[unused8]', '[unused9]', '[unused10]', '[unused11]', '[unused12]', '[unused13]', '[unused14]', '[unused15]', '[unused16]', '[unused17]', '[unused18]', '[unused19]', '[unused20]', '[unused21]', '[unused22]', '[unused23]', '[unused24]', '[unused25]', '[unused26]', '[unused27]', '[unused28]', '[unused29]', '[unused30]', '[unused31]', '[unused32]', '[unused33]', '[unused34]', '[unused35]', '[unused36]', '[unused37]', '[unused38]', '[unused39]', '[unused40]', '[unused41]', '[unused42]', '[unused43]', '[unused44]', '[unused45]', '[unused46]', '[unused47]', '[unused48]', '[unused49]', '[unused50]', '[unused51]', '[unused52]', '[unused53]', '[unused54]', '[unused55]', '[unused56]', '[unused57]', '[unused58]', '[unused59]', '[unused60]', '[unused61]', '[unused62]', '[unused63]', '[unused64]', '[unused65]', '[unused66]', '[unused67]', '[unused68]', '[unused69]', '[unused70]', '[unused71]', '[unused72]', '[unused73]', '[unused74]', '[unused75]', '[unused76]', '[unused77]', '[unused78]', '[unused79]', '[unused80]', '[unused81]', '[unused82]', '[unused83]', '[unused84]', '[unused85]', '[unused86]', '[unused87]', '[unused88]', '[unused89]', '[unused90]', '[unused91]', '[unused92]', '[unused93]', '[unused94]', '[unused95]', '[unused96]', '[unused97]', '[unused98]', '[unused99]', '[unused100]', '[unused101]', '[unused102]', '[unused103]', '[unused104]', '[unused105]', '[unused106]', '[unused107]', '[unused108]', '[unused109]', '[unused110]', '[unused111]', '[unused112]', '[unused113]', '[unused114]', '[unused115]', '[unused116]', '[unused117]', '[unused118]', '[unused119]', '[unused120]', '[unused121]', '[unused122]', '[unused123]', '[unused124]', '[unused125]', '[unused126]', '[unused127]', '[unused128]', '[unused129]', '[unused130]', '[unused131]', '[unused132]', '[unused133]', '[unused134]', '[unused135]', '[unused136]', '[unused137]', '[unused138]', '[unused139]', '[unused140]', '[unused141]', '[unused142]', '[unused143]', '[unused144]', '[unused145]', '[unused146]', '[unused147]', '[unused148]', '[unused149]', '[unused150]', '[unused151]', '[unused152]', '[unused153]', '[unused154]', '[unused155]', '[unused156]', '[unused157]', '[unused158]', '[unused159]', '[unused160]', '[unused161]', '[unused162]', '[unused163]', '[unused164]', '[unused165]', '[unused166]', '[unused167]', '[unused168]', '[unused169]', '[unused170]', '[unused171]', '[unused172]', '[unused173]', '[unused174]', '[unused175]', '[unused176]', '[unused177]', '[unused178]', '[unused179]', '[unused180]', '[unused181]', '[unused182]', '[unused183]', '[unused184]', '[unused185]', '[unused186]', '[unused187]', '[unused188]', '[unused189]', '[unused190]', '[unused191]', '[unused192]', '[unused193]', '[unused194]', '[unused195]', '[unused196]', '[unused197]', '[unused198]', '[unused199]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XF_Q_0VTFzPv",
        "outputId": "3cdc7f8d-264a-4e8d-9698-66952422600a"
      },
      "source": [
        "#'/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model'\n",
        "\n",
        "from transformers import BertTokenizer, AlbertTokenizer\n",
        "\n",
        "albet_tokenizer_model = '/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model'\n",
        "\n",
        "tokenizer = AlbertTokenizer.from_pretrained(albet_tokenizer_model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "QB0SlhA4GMQQ",
        "outputId": "0d1ecff0-fc3f-4426-a8e8-208382164e24"
      },
      "source": [
        "op = tokenizer.encode(\"나는 오늘 학교에 간다.\")\n",
        "print(op)\n",
        "tokenizer.decode(op)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5, 157, 491, 395, 740, 1614, 1723, 11640, 6]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] 나는 오늘 학교에 간다.[SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMDfH8GZF_mK",
        "outputId": "2cde659c-5c7e-4af8-e240-8930cf1746bf"
      },
      "source": [
        "# tokenizer에 special token 추가\n",
        "special_tokens_dict = {'additional_special_tokens': user_defined_symbols}\n",
        "tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "# check tokenizer vocab with special tokens\n",
        "print('check special tokens : %s'%tokenizer.all_special_tokens[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check special tokens : ['[CLS]', '[SEP]', '<unk>', '<pad>', '[MASK]', '[BOS]', '[EOS]', '[UNK0]', '[UNK1]', '[UNK2]', '[UNK3]', '[UNK4]', '[UNK5]', '[UNK6]', '[UNK7]', '[UNK8]', '[UNK9]', '[unused0]', '[unused1]', '[unused2]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Inr3cDwQG6Fs",
        "outputId": "5daeb04b-e77e-48ca-ecec-fcbdcd9b38b3"
      },
      "source": [
        "# save tokenizer model with special tokens\n",
        "tokenizer.save_pretrained(albet_tokenizer_model+'_special2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/spiece.model',\n",
              " '/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwhlWrXXHr6L"
      },
      "source": [
        "tokenizer = AlbertTokenizer.from_pretrained(albet_tokenizer_model+'_special2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgHhYsZbH3zr",
        "outputId": "42e9e39a-7484-4988-bd25-81db4c90b42a"
      },
      "source": [
        "op = tokenizer(\"나는 오늘 학교에 간다.\", return_tensors=\"pt\")\n",
        "print(op)\n",
        "print(\"Tokens (str)      : {}\".format([tokenizer.convert_ids_to_tokens(s) for s in op['input_ids'].tolist()[0]]))\n",
        "print(\"Tokens (int)      : {}\".format(op['input_ids'].tolist()[0]))\n",
        "print(\"Tokens (attn_mask): {}\\n\".format(op['attention_mask'].tolist()[0]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[    5,   157,   491,   395,   740,  1614,  1723, 11640,     6]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "Tokens (str)      : ['[CLS]', '▁나', '는', '▁오늘', '▁학교', '에', '▁간다', '.', '[SEP]']\n",
            "Tokens (int)      : [5, 157, 491, 395, 740, 1614, 1723, 11640, 6]\n",
            "Tokens (attn_mask): [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paElX_hhJAoh",
        "outputId": "15c94fa8-f098-47e8-b3ea-69022323773b"
      },
      "source": [
        "#Checking vocabulary size\n",
        "vocab_size=tokenizer.vocab_size ; vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "9RPI1UerOSCB",
        "outputId": "be3cd8b1-cb77-4de4-9979-40c906ebc89b"
      },
      "source": [
        "import json\n",
        "\n",
        "config = {\n",
        "    \"_name_or_path\": \"dolmani38/albert-xlarge-kor-v1\",\n",
        "    \"architectures\": [\n",
        "        \"AlbertModel\"\n",
        "    ],\n",
        "    \"attention_probs_dropout_prob\": 0,\n",
        "    \"bos_token_id\": 2,\n",
        "    \"classifier_dropout_prob\": 0.1,\n",
        "    \"down_scale_factor\": 1,\n",
        "    \"embedding_size\": 128,\n",
        "    \"eos_token_id\": 3,\n",
        "    \"gap_size\": 0,\n",
        "    \"hidden_act\": \"gelu_new\",\n",
        "    \"hidden_dropout_prob\": 0,\n",
        "    \"hidden_size\": 2048,\n",
        "    \"initializer_range\": 0.02,\n",
        "    \"inner_group_num\": 1,\n",
        "    \"intermediate_size\": 8192,\n",
        "    \"layer_norm_eps\": 1e-12,\n",
        "    \"max_position_embeddings\": 512,\n",
        "    \"model_type\": \"albert\",\n",
        "    \"net_structure_type\": 0,\n",
        "    \"num_attention_heads\": 16,\n",
        "    \"num_hidden_groups\": 1,\n",
        "    \"num_hidden_layers\": 24,\n",
        "    \"num_memory_blocks\": 0,\n",
        "    \"pad_token_id\": 0,\n",
        "    \"position_embedding_type\": \"absolute\",\n",
        "    \"type_vocab_size\": 2,\n",
        "\t\"vocab_size\": vocab_size\n",
        "}\n",
        "with open(albet_tokenizer_model + \"_special2/config.json\", 'w') as fp:\n",
        "    json.dump(config, fp)\n",
        "\n",
        "\n",
        "#Configuration for tokenizer.\n",
        "#Note: I set do_lower_case: False, and keep_accents:True\n",
        "# Opening JSON file\n",
        "f = open(albet_tokenizer_model+ \"_special2/tokenizer_config.json\")\n",
        "   \n",
        "# returns JSON object as \n",
        "# a dictionary\n",
        "tokenizer_config = json.load(f)\n",
        "\n",
        "tokenizer_config['max_len'] = 512\n",
        "tokenizer_config['model_type'] = 'albert'\n",
        "tokenizer_config['do_lower_case'] = False\n",
        "tokenizer_config['keep_accents'] = True\n",
        "\n",
        "with open(albet_tokenizer_model+ \"_special2/tokenizer_config.json\", 'w') as outfile:\n",
        "    json.dump(tokenizer_config, outfile)\n",
        "'''\n",
        "tokenizer_config = {\n",
        "\t\"max_len\": 512,\n",
        "\t\"model_type\": \"albert\",\n",
        "\t\"do_lower_case\":False, \n",
        "\t\"keep_accents\":True\n",
        "}\n",
        "with open(albet_tokenizer_model+ \"_special/tokenizer_config.json\", 'w') as fp:\n",
        "    json.dump(tokenizer_config, fp)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ntokenizer_config = {\\n\\t\"max_len\": 512,\\n\\t\"model_type\": \"albert\",\\n\\t\"do_lower_case\":False, \\n\\t\"keep_accents\":True\\n}\\nwith open(albet_tokenizer_model+ \"_special/tokenizer_config.json\", \\'w\\') as fp:\\n    json.dump(tokenizer_config, fp)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdjOOoG6QX2p",
        "outputId": "5d9e422a-72d0-4c1b-8dbb-d8f60e856976"
      },
      "source": [
        "\n",
        "#To train from scratch\n",
        "!python /content/transformers/examples/pytorch/language-modeling/run_mlm.py \\\n",
        "        --model_type albert-xlarge \\\n",
        "        --config_name /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/ \\\n",
        "        --tokenizer_name /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/ \\\n",
        "        --train_file /content/drive/MyDrive/Tokenizer_train/data/train_tokenizer.txt \\\n",
        "        --output_dir /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model \\\n",
        "        --do_train \\\n",
        "        --line_by_line \\\n",
        "        --save_steps 500 \\\n",
        "        --logging_steps 500 \\\n",
        "        --save_total_limit 2 \\\n",
        "        --num_train_epochs 1 \\\n",
        "        --seed 108 \\\n",
        "        --logging_dir /content/drive/MyDrive/Tokenizer_train/logs"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-18 06:40:39.797228: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "05/18/2021 06:40:50 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "05/18/2021 06:40:50 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model, overwrite_output_dir=False, do_train=True, do_eval=False, do_predict=False, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=/content/drive/MyDrive/Tokenizer_train/logs, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=500, save_strategy=IntervalStrategy.STEPS, save_steps=500, save_total_limit=2, no_cuda=False, seed=108, fp16=False, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name=length, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, _n_gpu=1, mp_parameters=)\n",
            "05/18/2021 06:40:51 - WARNING - datasets.builder -   Using custom data configuration default-f65fc3c826c08b2e\n",
            "05/18/2021 06:40:51 - WARNING - datasets.builder -   Reusing dataset text (/root/.cache/huggingface/datasets/text/default-f65fc3c826c08b2e/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
            "[INFO|configuration_utils.py:515] 2021-05-18 06:40:52,182 >> loading configuration file /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/config.json\n",
            "[INFO|configuration_utils.py:553] 2021-05-18 06:40:52,183 >> Model config AlbertConfig {\n",
            "  \"_name_or_path\": \"dolmani38/albert-xlarge-kor-v1\",\n",
            "  \"architectures\": [\n",
            "    \"AlbertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.7.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30015\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:515] 2021-05-18 06:40:52,280 >> loading configuration file /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/config.json\n",
            "[INFO|configuration_utils.py:553] 2021-05-18 06:40:52,280 >> Model config AlbertConfig {\n",
            "  \"_name_or_path\": \"dolmani38/albert-xlarge-kor-v1\",\n",
            "  \"architectures\": [\n",
            "    \"AlbertModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 2048,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 8192,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.7.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30015\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1651] 2021-05-18 06:40:52,281 >> Didn't find file /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/tokenizer.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-05-18 06:40:52,282 >> loading file /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/spiece.model\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-05-18 06:40:52,282 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-05-18 06:40:52,282 >> loading file /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/added_tokens.json\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-05-18 06:40:52,282 >> loading file /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1715] 2021-05-18 06:40:52,282 >> loading file /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/tokenizer_config.json\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,332 >> Adding <pad> to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,332 >> Adding [unused100] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,332 >> Adding [unused101] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,332 >> Adding [unused102] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,333 >> Adding [unused103] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,333 >> Adding [unused104] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,333 >> Adding [unused105] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,333 >> Adding [unused106] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,333 >> Adding [unused107] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,333 >> Adding [unused108] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,333 >> Adding [unused109] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,333 >> Adding [unused110] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,333 >> Adding [unused111] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,333 >> Adding [unused112] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,333 >> Adding [unused113] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,333 >> Adding [unused114] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,333 >> Adding [unused115] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,333 >> Adding [unused116] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,333 >> Adding [unused117] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,334 >> Adding [unused118] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,334 >> Adding [unused119] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,334 >> Adding [unused120] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,334 >> Adding [unused121] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,334 >> Adding [unused122] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,334 >> Adding [unused123] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,334 >> Adding [unused124] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,334 >> Adding [unused125] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,334 >> Adding [unused126] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,334 >> Adding [unused127] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,334 >> Adding [unused128] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,334 >> Adding [unused129] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,334 >> Adding [unused130] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,334 >> Adding [unused131] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,334 >> Adding [unused132] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,334 >> Adding [unused133] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,335 >> Adding [unused134] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,335 >> Adding [unused135] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,335 >> Adding [unused136] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,335 >> Adding [unused137] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,335 >> Adding [unused138] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,335 >> Adding [unused139] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,335 >> Adding [unused140] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,335 >> Adding [unused141] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,335 >> Adding [unused142] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,335 >> Adding [unused143] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,335 >> Adding [unused144] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,335 >> Adding [unused145] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,335 >> Adding [unused146] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,335 >> Adding [unused147] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,335 >> Adding [unused148] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,336 >> Adding [unused149] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,336 >> Adding [unused150] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,336 >> Adding [unused151] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,336 >> Adding [unused152] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,336 >> Adding [unused153] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,336 >> Adding [unused154] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,336 >> Adding [unused155] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,336 >> Adding [unused156] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,336 >> Adding [unused157] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,336 >> Adding [unused158] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,336 >> Adding [unused159] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,336 >> Adding [unused160] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,336 >> Adding [unused161] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,336 >> Adding [unused162] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,337 >> Adding [unused163] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,337 >> Adding [unused164] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,337 >> Adding [unused165] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,337 >> Adding [unused166] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,337 >> Adding [unused167] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,337 >> Adding [unused168] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,337 >> Adding [unused169] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,337 >> Adding [unused170] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,337 >> Adding [unused171] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,337 >> Adding [unused172] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,337 >> Adding [unused173] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,337 >> Adding [unused174] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,337 >> Adding [unused175] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,338 >> Adding [unused176] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,338 >> Adding [unused177] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,338 >> Adding [unused178] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,338 >> Adding [unused179] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,338 >> Adding [unused180] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,338 >> Adding [unused181] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,338 >> Adding [unused182] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,338 >> Adding [unused183] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,338 >> Adding [unused184] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,338 >> Adding [unused185] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,338 >> Adding [unused186] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,338 >> Adding [unused187] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,338 >> Adding [unused188] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,339 >> Adding [unused189] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,339 >> Adding [unused190] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,339 >> Adding [unused191] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,339 >> Adding [unused192] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,339 >> Adding [unused193] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,339 >> Adding [unused194] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,339 >> Adding [unused195] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,339 >> Adding [unused196] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,339 >> Adding [unused197] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,339 >> Adding [unused198] to the vocabulary\n",
            "[INFO|tokenization_utils.py:207] 2021-05-18 06:40:52,339 >> Adding [unused199] to the vocabulary\n",
            "05/18/2021 06:40:52 - INFO - __main__ -   Training new model from scratch\n",
            "05/18/2021 06:40:54 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /root/.cache/huggingface/datasets/text/default-f65fc3c826c08b2e/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-5b08f5c71a95ce69.arrow\n",
            "[INFO|trainer.py:1043] 2021-05-18 06:40:58,689 >> Loading model from /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-107500).\n",
            "[INFO|trainer.py:516] 2021-05-18 06:41:00,391 >> The following columns in the training set  don't have a corresponding argument in `AlbertForMaskedLM.forward` and have been ignored: special_tokens_mask.\n",
            "[INFO|trainer.py:1145] 2021-05-18 06:41:01,409 >> ***** Running training *****\n",
            "[INFO|trainer.py:1146] 2021-05-18 06:41:01,409 >>   Num examples = 1017766\n",
            "[INFO|trainer.py:1147] 2021-05-18 06:41:01,409 >>   Num Epochs = 1\n",
            "[INFO|trainer.py:1148] 2021-05-18 06:41:01,409 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:1149] 2021-05-18 06:41:01,409 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "[INFO|trainer.py:1150] 2021-05-18 06:41:01,409 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1151] 2021-05-18 06:41:01,409 >>   Total optimization steps = 127221\n",
            "[INFO|trainer.py:1171] 2021-05-18 06:41:01,411 >>   Continuing training from checkpoint, will skip to saved global_step\n",
            "[INFO|trainer.py:1172] 2021-05-18 06:41:01,411 >>   Continuing training from epoch 0\n",
            "[INFO|trainer.py:1173] 2021-05-18 06:41:01,412 >>   Continuing training from global step 107500\n",
            "[INFO|trainer.py:1176] 2021-05-18 06:41:01,412 >>   Will skip the first 0 epochs then the first 107500 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n",
            "Skipping the first batches:   0% 0/107500 [00:00<?, ?it/s]\n",
            "Skipping the first batches: 100% 107479/107500 [07:21<00:00, 280.40it/s]\n",
            "Skipping the first batches: 100% 107500/107500 [07:21<00:00, 243.71it/s]\n",
            "{'loss': 7.1028, 'learning_rate': 7.554177376376542e-06, 'epoch': 0.85}\n",
            " 85% 108000/127221 [09:03<1:10:23,  4.55it/s][INFO|trainer.py:1885] 2021-05-18 06:50:05,359 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-108000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 06:50:05,365 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-108000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 06:50:06,166 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-108000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 06:50:06,170 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-108000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 06:50:06,174 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-108000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 06:50:08,343 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-107000] due to args.save_total_limit\n",
            "{'loss': 7.1049, 'learning_rate': 7.3576689383042115e-06, 'epoch': 0.85}\n",
            " 85% 108500/127221 [10:52<58:29,  5.33it/s][INFO|trainer.py:1885] 2021-05-18 06:51:53,989 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-108500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 06:51:53,995 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-108500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 06:51:54,769 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-108500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 06:51:54,773 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-108500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 06:51:54,777 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-108500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 06:51:56,791 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-107500] due to args.save_total_limit\n",
            "{'loss': 7.0892, 'learning_rate': 7.16116050023188e-06, 'epoch': 0.86}\n",
            " 86% 109000/127221 [12:41<59:14,  5.13it/s][INFO|trainer.py:1885] 2021-05-18 06:53:42,512 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-109000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 06:53:42,517 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-109000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 06:53:43,310 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-109000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 06:53:43,316 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-109000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 06:53:43,320 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-109000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 06:53:45,299 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-108000] due to args.save_total_limit\n",
            "{'loss': 7.0622, 'learning_rate': 6.964652062159549e-06, 'epoch': 0.86}\n",
            " 86% 109500/127221 [14:27<1:10:04,  4.21it/s][INFO|trainer.py:1885] 2021-05-18 06:55:28,719 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-109500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 06:55:28,724 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-109500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 06:55:29,503 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-109500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 06:55:29,508 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-109500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 06:55:29,512 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-109500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 06:55:31,508 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-108500] due to args.save_total_limit\n",
            "{'loss': 7.0249, 'learning_rate': 6.7681436240872185e-06, 'epoch': 0.86}\n",
            " 86% 110000/127221 [16:16<1:12:35,  3.95it/s][INFO|trainer.py:1885] 2021-05-18 06:57:17,846 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-110000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 06:57:17,853 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-110000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 06:57:18,630 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-110000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 06:57:18,636 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-110000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 06:57:18,641 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-110000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 06:57:20,631 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-109000] due to args.save_total_limit\n",
            "{'loss': 7.072, 'learning_rate': 6.571635186014888e-06, 'epoch': 0.87}\n",
            " 87% 110500/127221 [18:03<48:53,  5.70it/s][INFO|trainer.py:1885] 2021-05-18 06:59:05,144 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-110500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 06:59:05,150 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-110500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 06:59:05,927 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-110500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 06:59:05,931 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-110500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 06:59:05,935 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-110500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 06:59:07,835 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-109500] due to args.save_total_limit\n",
            "{'loss': 7.0848, 'learning_rate': 6.375126747942557e-06, 'epoch': 0.87}\n",
            " 87% 111000/127221 [19:50<55:26,  4.88it/s][INFO|trainer.py:1885] 2021-05-18 07:00:52,358 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-111000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:00:52,367 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-111000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:00:53,139 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-111000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:00:53,146 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-111000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:00:53,152 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-111000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:00:56,217 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-110000] due to args.save_total_limit\n",
            "{'loss': 7.06, 'learning_rate': 6.178618309870226e-06, 'epoch': 0.88}\n",
            " 88% 111500/127221 [21:38<46:03,  5.69it/s][INFO|trainer.py:1885] 2021-05-18 07:02:39,767 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-111500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:02:39,772 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-111500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:02:40,561 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-111500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:02:40,566 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-111500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:02:40,570 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-111500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:02:42,518 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-110500] due to args.save_total_limit\n",
            "{'loss': 7.093, 'learning_rate': 5.9821098717978955e-06, 'epoch': 0.88}\n",
            " 88% 112000/127221 [23:25<1:01:50,  4.10it/s][INFO|trainer.py:1885] 2021-05-18 07:04:27,036 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-112000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:04:27,042 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-112000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:04:27,799 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-112000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:04:27,803 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-112000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:04:27,807 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-112000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:04:29,948 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-111000] due to args.save_total_limit\n",
            "{'loss': 7.0791, 'learning_rate': 5.785601433725565e-06, 'epoch': 0.88}\n",
            " 88% 112500/127221 [25:12<46:47,  5.24it/s][INFO|trainer.py:1885] 2021-05-18 07:06:14,167 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-112500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:06:14,172 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-112500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:06:14,931 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-112500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:06:14,950 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-112500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:06:14,954 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-112500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:06:16,917 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-111500] due to args.save_total_limit\n",
            "{'loss': 7.0911, 'learning_rate': 5.589092995653233e-06, 'epoch': 0.89}\n",
            " 89% 113000/127221 [26:59<41:38,  5.69it/s][INFO|trainer.py:1885] 2021-05-18 07:08:00,733 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-113000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:08:00,738 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-113000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:08:01,490 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-113000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:08:01,495 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-113000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:08:01,498 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-113000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:08:03,508 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-112000] due to args.save_total_limit\n",
            "{'loss': 7.0124, 'learning_rate': 5.3925845575809024e-06, 'epoch': 0.89}\n",
            " 89% 113500/127221 [28:45<58:14,  3.93it/s][INFO|trainer.py:1885] 2021-05-18 07:09:46,609 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-113500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:09:46,615 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-113500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:09:47,371 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-113500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:09:47,376 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-113500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:09:47,379 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-113500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:09:50,404 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-112500] due to args.save_total_limit\n",
            "{'loss': 7.0589, 'learning_rate': 5.1960761195085725e-06, 'epoch': 0.9}\n",
            " 90% 114000/127221 [30:32<41:05,  5.36it/s][INFO|trainer.py:1885] 2021-05-18 07:11:33,950 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-114000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:11:33,957 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-114000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:11:34,701 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-114000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:11:34,707 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-114000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:11:34,711 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-114000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:11:36,825 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-113000] due to args.save_total_limit\n",
            "{'loss': 7.0348, 'learning_rate': 4.999567681436241e-06, 'epoch': 0.9}\n",
            " 90% 114500/127221 [32:24<41:30,  5.11it/s][INFO|trainer.py:1885] 2021-05-18 07:13:26,076 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-114500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:13:26,081 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-114500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:13:26,850 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-114500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:13:26,854 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-114500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:13:26,858 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-114500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:13:29,201 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-113500] due to args.save_total_limit\n",
            "{'loss': 7.0653, 'learning_rate': 4.80305924336391e-06, 'epoch': 0.9}\n",
            " 90% 115000/127221 [34:11<40:07,  5.08it/s][INFO|trainer.py:1885] 2021-05-18 07:15:12,497 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-115000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:15:12,505 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-115000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:15:13,278 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-115000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:15:13,287 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-115000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:15:13,291 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-115000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:15:15,174 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-114000] due to args.save_total_limit\n",
            "{'loss': 7.0796, 'learning_rate': 4.6065508052915795e-06, 'epoch': 0.91}\n",
            " 91% 115500/127221 [35:57<40:33,  4.82it/s][INFO|trainer.py:1885] 2021-05-18 07:16:59,372 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-115500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:16:59,377 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-115500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:17:00,124 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-115500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:17:00,130 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-115500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:17:00,400 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-115500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:17:02,651 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-114500] due to args.save_total_limit\n",
            "{'loss': 7.1055, 'learning_rate': 4.410042367219249e-06, 'epoch': 0.91}\n",
            " 91% 116000/127221 [37:46<32:20,  5.78it/s][INFO|trainer.py:1885] 2021-05-18 07:18:47,520 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-116000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:18:47,530 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-116000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:18:48,307 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-116000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:18:48,317 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-116000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:18:48,331 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-116000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:18:51,034 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-115000] due to args.save_total_limit\n",
            "{'loss': 7.0643, 'learning_rate': 4.213533929146918e-06, 'epoch': 0.92}\n",
            " 92% 116500/127221 [39:34<32:29,  5.50it/s][INFO|trainer.py:1885] 2021-05-18 07:20:35,680 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-116500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:20:35,685 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-116500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:20:36,457 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-116500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:20:36,476 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-116500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:20:36,493 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-116500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:20:39,176 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-115500] due to args.save_total_limit\n",
            "{'loss': 7.104, 'learning_rate': 4.017025491074587e-06, 'epoch': 0.92}\n",
            " 92% 117000/127221 [41:25<29:58,  5.68it/s][INFO|trainer.py:1885] 2021-05-18 07:22:27,418 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-117000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:22:27,423 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-117000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:22:28,173 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-117000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:22:28,180 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-117000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:22:28,188 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-117000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:22:30,217 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-116000] due to args.save_total_limit\n",
            "{'loss': 7.0613, 'learning_rate': 3.820517053002256e-06, 'epoch': 0.92}\n",
            " 92% 117500/127221 [43:14<37:38,  4.30it/s][INFO|trainer.py:1885] 2021-05-18 07:24:15,846 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-117500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:24:15,851 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-117500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:24:16,662 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-117500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:24:16,671 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-117500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:24:16,680 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-117500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:24:18,791 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-116500] due to args.save_total_limit\n",
            "{'loss': 7.1158, 'learning_rate': 3.6240086149299254e-06, 'epoch': 0.93}\n",
            " 93% 118000/127221 [44:58<27:45,  5.54it/s][INFO|trainer.py:1885] 2021-05-18 07:25:59,812 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-118000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:25:59,819 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-118000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:26:00,574 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-118000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:26:00,822 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-118000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:26:00,833 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-118000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:26:02,823 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-117000] due to args.save_total_limit\n",
            "{'loss': 7.0829, 'learning_rate': 3.4275001768575946e-06, 'epoch': 0.93}\n",
            " 93% 118500/127221 [46:40<25:03,  5.80it/s][INFO|trainer.py:1885] 2021-05-18 07:27:42,226 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-118500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:27:42,232 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-118500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:27:42,989 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-118500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:27:43,001 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-118500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:27:43,009 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-118500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:27:45,531 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-117500] due to args.save_total_limit\n",
            "{'loss': 7.0811, 'learning_rate': 3.2309917387852634e-06, 'epoch': 0.94}\n",
            " 94% 119000/127221 [48:25<33:35,  4.08it/s][INFO|trainer.py:1885] 2021-05-18 07:29:27,228 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-119000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:29:27,233 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-119000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:29:28,017 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-119000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:29:28,030 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-119000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:29:28,035 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-119000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:29:30,043 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-118000] due to args.save_total_limit\n",
            "{'loss': 7.0854, 'learning_rate': 3.0344833007129327e-06, 'epoch': 0.94}\n",
            " 94% 119500/127221 [50:12<25:57,  4.96it/s][INFO|trainer.py:1885] 2021-05-18 07:31:14,168 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-119500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:31:14,174 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-119500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:31:14,922 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-119500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:31:14,931 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-119500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:31:14,947 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-119500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:31:16,883 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-118500] due to args.save_total_limit\n",
            "{'loss': 7.0903, 'learning_rate': 2.837974862640602e-06, 'epoch': 0.94}\n",
            " 94% 120000/127221 [52:00<21:01,  5.72it/s][INFO|trainer.py:1885] 2021-05-18 07:33:01,608 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-120000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:33:01,613 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-120000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:33:02,374 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-120000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:33:02,381 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-120000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:33:02,385 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-120000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:33:04,416 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-119000] due to args.save_total_limit\n",
            "{'loss': 7.0842, 'learning_rate': 2.6414664245682712e-06, 'epoch': 0.95}\n",
            " 95% 120500/127221 [53:45<24:50,  4.51it/s][INFO|trainer.py:1885] 2021-05-18 07:34:47,162 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-120500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:34:47,167 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-120500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:34:47,929 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-120500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:34:48,114 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-120500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:34:48,157 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-120500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:34:50,100 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-119500] due to args.save_total_limit\n",
            "{'loss': 7.0904, 'learning_rate': 2.4449579864959405e-06, 'epoch': 0.95}\n",
            " 95% 121000/127221 [55:35<20:14,  5.12it/s][INFO|trainer.py:1885] 2021-05-18 07:36:37,354 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-121000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:36:37,358 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-121000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:36:38,129 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-121000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:36:38,138 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-121000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:36:38,143 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-121000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:36:40,783 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-120000] due to args.save_total_limit\n",
            "{'loss': 7.0787, 'learning_rate': 2.2484495484236093e-06, 'epoch': 0.96}\n",
            " 96% 121500/127221 [57:23<18:46,  5.08it/s][INFO|trainer.py:1885] 2021-05-18 07:38:25,054 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-121500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:38:25,059 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-121500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:38:25,825 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-121500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:38:25,831 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-121500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:38:25,836 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-121500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:38:29,939 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-120500] due to args.save_total_limit\n",
            "{'loss': 7.0757, 'learning_rate': 2.0519411103512786e-06, 'epoch': 0.96}\n",
            " 96% 122000/127221 [59:12<16:51,  5.16it/s][INFO|trainer.py:1885] 2021-05-18 07:40:13,721 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-122000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:40:13,727 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-122000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:40:14,476 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-122000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:40:14,489 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-122000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:40:14,495 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-122000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:40:16,529 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-121000] due to args.save_total_limit\n",
            "{'loss': 7.1159, 'learning_rate': 1.8554326722789478e-06, 'epoch': 0.96}\n",
            " 96% 122500/127221 [1:01:01<15:38,  5.03it/s][INFO|trainer.py:1885] 2021-05-18 07:42:03,308 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-122500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:42:03,314 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-122500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:42:04,089 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-122500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:42:04,095 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-122500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:42:04,100 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-122500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:42:05,975 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-121500] due to args.save_total_limit\n",
            "{'loss': 7.0818, 'learning_rate': 1.6589242342066169e-06, 'epoch': 0.97}\n",
            " 97% 123000/127221 [1:02:48<16:18,  4.31it/s][INFO|trainer.py:1885] 2021-05-18 07:43:50,218 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-123000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:43:50,224 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-123000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:43:51,143 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-123000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:43:51,229 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-123000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:43:51,240 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-123000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:43:53,280 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-122000] due to args.save_total_limit\n",
            "{'loss': 7.1071, 'learning_rate': 1.4624157961342862e-06, 'epoch': 0.97}\n",
            " 97% 123500/127221 [1:04:35<17:30,  3.54it/s][INFO|trainer.py:1885] 2021-05-18 07:45:37,214 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-123500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:45:37,219 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-123500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:45:37,988 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-123500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:45:37,995 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-123500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:45:38,007 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-123500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:45:40,517 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-122500] due to args.save_total_limit\n",
            "{'loss': 7.0993, 'learning_rate': 1.2659073580619552e-06, 'epoch': 0.97}\n",
            " 97% 124000/127221 [1:06:21<12:28,  4.31it/s][INFO|trainer.py:1885] 2021-05-18 07:47:22,690 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-124000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:47:22,696 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-124000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:47:23,464 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-124000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:47:23,473 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-124000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:47:23,477 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-124000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:47:26,428 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-123000] due to args.save_total_limit\n",
            "{'loss': 7.0743, 'learning_rate': 1.0693989199896243e-06, 'epoch': 0.98}\n",
            " 98% 124500/127221 [1:08:09<08:05,  5.60it/s][INFO|trainer.py:1885] 2021-05-18 07:49:10,978 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-124500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:49:10,983 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-124500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:49:11,718 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-124500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:49:11,725 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-124500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:49:11,731 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-124500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:49:13,779 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-123500] due to args.save_total_limit\n",
            "{'loss': 7.0916, 'learning_rate': 8.728904819172936e-07, 'epoch': 0.98}\n",
            " 98% 125000/127221 [1:09:58<08:22,  4.42it/s][INFO|trainer.py:1885] 2021-05-18 07:50:59,940 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-125000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:50:59,946 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-125000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:51:00,705 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-125000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:51:00,716 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-125000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:51:00,728 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-125000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:51:02,747 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-124000] due to args.save_total_limit\n",
            "{'loss': 7.0903, 'learning_rate': 6.763820438449627e-07, 'epoch': 0.99}\n",
            " 99% 125500/127221 [1:11:43<07:01,  4.09it/s][INFO|trainer.py:1885] 2021-05-18 07:52:44,762 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-125500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:52:44,768 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-125500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:52:45,530 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-125500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:52:45,562 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-125500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:52:45,566 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-125500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:52:47,596 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-124500] due to args.save_total_limit\n",
            "{'loss': 7.1045, 'learning_rate': 4.798736057726319e-07, 'epoch': 0.99}\n",
            " 99% 126000/127221 [1:13:30<04:06,  4.95it/s][INFO|trainer.py:1885] 2021-05-18 07:54:32,340 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-126000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:54:32,345 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-126000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:54:33,111 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-126000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:54:33,117 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-126000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:54:33,123 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-126000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:54:35,512 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-125000] due to args.save_total_limit\n",
            "{'loss': 7.0805, 'learning_rate': 2.833651677003011e-07, 'epoch': 0.99}\n",
            " 99% 126500/127221 [1:15:18<02:09,  5.57it/s][INFO|trainer.py:1885] 2021-05-18 07:56:20,241 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-126500\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:56:20,247 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-126500/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:56:21,047 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-126500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:56:21,055 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-126500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:56:21,060 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-126500/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:56:24,044 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-125500] due to args.save_total_limit\n",
            "{'loss': 7.051, 'learning_rate': 8.685672962797023e-08, 'epoch': 1.0}\n",
            "100% 127000/127221 [1:17:08<00:43,  5.07it/s][INFO|trainer.py:1885] 2021-05-18 07:58:09,804 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-127000\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:58:09,809 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-127000/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:58:10,575 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-127000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:58:10,580 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-127000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:58:10,584 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-127000/special_tokens_map.json\n",
            "[INFO|trainer.py:1953] 2021-05-18 07:58:12,598 >> Deleting older checkpoint [/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/checkpoint-126000] due to args.save_total_limit\n",
            "100% 127221/127221 [1:17:55<00:00,  5.68it/s][INFO|trainer.py:1341] 2021-05-18 07:58:56,448 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 4675.0391, 'train_samples_per_second': 27.213, 'epoch': 1.0}\n",
            "100% 127221/127221 [1:17:55<00:00, 27.21it/s]\n",
            "[INFO|trainer.py:1885] 2021-05-18 07:58:56,949 >> Saving model checkpoint to /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model\n",
            "[INFO|configuration_utils.py:351] 2021-05-18 07:58:56,954 >> Configuration saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/config.json\n",
            "[INFO|modeling_utils.py:889] 2021-05-18 07:58:57,653 >> Model weights saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1924] 2021-05-18 07:58:57,662 >> tokenizer config file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1930] 2021-05-18 07:58:57,666 >> Special tokens file saved in /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model/special_tokens_map.json\n",
            "[INFO|trainer_pt_utils.py:907] 2021-05-18 07:58:57,734 >> ***** train metrics *****\n",
            "[INFO|trainer_pt_utils.py:912] 2021-05-18 07:58:57,734 >>   epoch                      =        1.0\n",
            "[INFO|trainer_pt_utils.py:912] 2021-05-18 07:58:57,734 >>   init_mem_cpu_alloc_delta   =     2640MB\n",
            "[INFO|trainer_pt_utils.py:912] 2021-05-18 07:58:57,735 >>   init_mem_cpu_peaked_delta  =        0MB\n",
            "[INFO|trainer_pt_utils.py:912] 2021-05-18 07:58:57,735 >>   init_mem_gpu_alloc_delta   =      209MB\n",
            "[INFO|trainer_pt_utils.py:912] 2021-05-18 07:58:57,735 >>   init_mem_gpu_peaked_delta  =        0MB\n",
            "[INFO|trainer_pt_utils.py:912] 2021-05-18 07:58:57,735 >>   train_mem_cpu_alloc_delta  =      141MB\n",
            "[INFO|trainer_pt_utils.py:912] 2021-05-18 07:58:57,735 >>   train_mem_cpu_peaked_delta =       69MB\n",
            "[INFO|trainer_pt_utils.py:912] 2021-05-18 07:58:57,735 >>   train_mem_gpu_alloc_delta  =      627MB\n",
            "[INFO|trainer_pt_utils.py:912] 2021-05-18 07:58:57,735 >>   train_mem_gpu_peaked_delta =     7099MB\n",
            "[INFO|trainer_pt_utils.py:912] 2021-05-18 07:58:57,735 >>   train_runtime              = 1:17:55.03\n",
            "[INFO|trainer_pt_utils.py:912] 2021-05-18 07:58:57,735 >>   train_samples              =    1017766\n",
            "[INFO|trainer_pt_utils.py:912] 2021-05-18 07:58:57,735 >>   train_samples_per_second   =     27.213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R8TLMISRaPA",
        "outputId": "2695cc96-f049-4e23-ae19-0b7861a3ab6b"
      },
      "source": [
        "from transformers import AlbertTokenizerFast, AlbertModel\n",
        "\n",
        "tokenizer = AlbertTokenizerFast.from_pretrained('/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model')\n",
        "model = AlbertModel.from_pretrained('/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model were not used when initializing AlbertModel: ['predictions.bias', 'predictions.dense.bias', 'predictions.dense.weight', 'predictions.decoder.weight', 'predictions.LayerNorm.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias']\n",
            "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertModel were not initialized from the model checkpoint at /content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model and are newly initialized: ['albert.pooler.bias', 'albert.pooler.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4twnD81qaRR"
      },
      "source": [
        "tokenizer.save_pretrained('/content/drive/MyDrive/Tokenizer_train/albert-xlarge-kor')\n",
        "model.save_pretrained('/content/drive/MyDrive/Tokenizer_train/albert-xlarge-kor')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4ghZhMYuO38"
      },
      "source": [
        "# 기존 albert-kor-base 사용 \n",
        "\n",
        "https://huggingface.co/kykim/albert-kor-base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245,
          "referenced_widgets": [
            "44757a3a7afe4e4eb95e95f11e94baed",
            "fee20f84e6204e7bad616f22de2b85ba",
            "673b5f7827d7437f92e1f3240161aa5a",
            "9170fc91ba304ad8b6a4c2d2ccb31355",
            "e561f9e07090434cb77090aeddc4789a",
            "de0381976d7c4fc68b06665cbae12834",
            "6d81c8e6bbaa47139a9161791c49e526",
            "db5a8e04fa0949de9cfc76eb7494f9ca",
            "f6fb86e6f6914670968ad70d09ab5852",
            "bd03d7a79e02416ebcdb5f6193414fe3",
            "b656b044f5964b18a69be602cf391abf",
            "3bb580a2181641c48ca8a14da6e7c2a0",
            "4ceff003d619437d8ecae1bf080db110",
            "c807b711d5e84e2fb60db9716f57a004",
            "6c478a8fd1214967a49ba63b7a5f5c2d",
            "2a15c90485f04cdab63dcd9704bc68d7",
            "cc2d8144b76b471a824dddd49b6c5889",
            "51dca6c50af5412994758f1c854a78de",
            "2448a43b9a3645cebcabe6a5c21b0d6f",
            "0c511bccc20b4815a1ff1a54d40f94da",
            "508cd332718045e290ac9a43cf950af3",
            "42119f7a708b411b93a877db42feae49",
            "5dad0c302f7d4533ada1482eebc97809",
            "73e88e9c09f44e86a9ae023ec7f6ed21"
          ]
        },
        "id": "OCTh5ViFuWUs",
        "outputId": "f56a2dd5-3949-42b5-b5c2-64f8ca9009f5"
      },
      "source": [
        "from transformers import BertTokenizerFast, AlbertModel\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('kykim/albert-kor-base')\n",
        "model = AlbertModel.from_pretrained('kykim/albert-kor-base')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44757a3a7afe4e4eb95e95f11e94baed",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=344259.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6fb86e6f6914670968ad70d09ab5852",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=684.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc2d8144b76b471a824dddd49b6c5889",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=53325832.0, style=ProgressStyle(descrip…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at kykim/albert-kor-base were not used when initializing AlbertModel: ['predictions.dense.weight', 'predictions.LayerNorm.bias', 'predictions.bias', 'predictions.decoder.bias', 'predictions.decoder.weight', 'sop_classifier.classifier.bias', 'sop_classifier.classifier.weight', 'predictions.dense.bias', 'predictions.LayerNorm.weight']\n",
            "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfSy-90kvAqH",
        "outputId": "a771a469-dcab-4393-9de7-45c47785d1c7"
      },
      "source": [
        "tokenizer.save_pretrained('/content/drive/MyDrive/Tokenizer_train/albert-kor-base')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Tokenizer_train/albert-kor-base/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Tokenizer_train/albert-kor-base/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Tokenizer_train/albert-kor-base/vocab.txt',\n",
              " '/content/drive/MyDrive/Tokenizer_train/albert-kor-base/added_tokens.json',\n",
              " '/content/drive/MyDrive/Tokenizer_train/albert-kor-base/tokenizer.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEb3ISnMvXnA"
      },
      "source": [
        "model.save_pretrained('/content/drive/MyDrive/Tokenizer_train/albert-kor-base')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296,
          "referenced_widgets": [
            "900992c9731b494a836b090acd817255",
            "4a609fde633448e4abedf96a3ca46514",
            "aee229bbb2cb4014a2aaaa7de42ecadc",
            "804ff19fd0c34b33a64d3db138eee97b",
            "628451d485bb41b687e0388a3a0733d9",
            "04f37ec1ff4a455b84732cde635a7a32",
            "1210ff77115442c8adea202c2384ad7a",
            "daa84cb7428547dda7903cbeb1648392",
            "20e74878ee6d4169838f5ebcd9bf9105",
            "2b8569172ab848749ef1d1fbaaf12666",
            "4922360857c941f8ba39fa6b714f368d",
            "b38b917be9b24e0088cc29f43318e8e5",
            "34b650cda7e6401281b3d38a515a9bbc",
            "0c0903beadef4ee9980a15bc0fac1125",
            "2ff724f00db740828f6f3167b7586b6b",
            "d558b31da7c84edc86e1b08c0f9c44dd",
            "733866c92eec4255b38e995e9b7ba0b8",
            "13052ef80a744def9c3537a2ac0750c3",
            "5d3816317c6843efbd58e22c6ffea1e2",
            "b7f8684692d740c2a684aba285114e1b",
            "89cf8cf5c0554bb886a5749336ca8ee7",
            "dc2ea1c1d9a448cd84cd1af0c731e4fe",
            "c66d419b769649b18f80dba829755316",
            "aa3bc3bdaf5d48d5b678ca4cf01930cb",
            "1e942b3ef56f449299c8d22c98b5443d",
            "c0282cbb9c9c42ec910ecfe70e6bb49c",
            "978efca384e942b4aec18babdf2e9b6a",
            "6502ffd64d1940509266fa7d5890b669",
            "86da887a18b44fa1a450129f2c8986d7",
            "132e520423e94ef39e88cb0b872a006e",
            "3a5049dee38641f08f01c4c58e4a09c1",
            "8f07e69a62694d099a85e21b39328ecf"
          ]
        },
        "id": "d1eykQOfZPnN",
        "outputId": "6b7b0329-78bb-436c-ef30-bb63c17c331f"
      },
      "source": [
        "from transformers import AlbertTokenizer, AlbertModel\n",
        "\n",
        "tokenizer = AlbertTokenizer.from_pretrained('albert-xlarge-v2')\n",
        "model = AlbertModel.from_pretrained('albert-xlarge-v2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "900992c9731b494a836b090acd817255",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20e74878ee6d4169838f5ebcd9bf9105",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1312669.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "733866c92eec4255b38e995e9b7ba0b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=685.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e942b3ef56f449299c8d22c98b5443d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=236197176.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at albert-xlarge-v2 were not used when initializing AlbertModel: ['predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.dense.bias', 'predictions.bias', 'predictions.dense.weight']\n",
            "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeZAA14kZpLO"
      },
      "source": [
        "tokenizer.save_pretrained('/content/drive/MyDrive/Tokenizer_train/albert-kor-xlarge')\n",
        "model.save_pretrained('/content/drive/MyDrive/Tokenizer_train/albert-kor-xlarge')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13JDIF67_hWF"
      },
      "source": [
        "# 여기서부터 새로운 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elahPhO3vijH"
      },
      "source": [
        "from transformers import AlbertTokenizerFast, AlbertForQuestionAnswering\n",
        "\n",
        "tokenizer = AlbertTokenizerFast.from_pretrained('/content/drive/MyDrive/Tokenizer_train/albert-xlarge-kor')\n",
        "#model = AlbertForQuestionAnswering.from_pretrained('/content/drive/MyDrive/Tokenizer_train/albert-kor-base')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiwgEyUiv3E1",
        "outputId": "4873ba0e-3e58-42ee-b8c1-15acb5d438fe"
      },
      "source": [
        "op = tokenizer(\"나는 오늘 학교에 간다.\", return_tensors=\"pt\")\n",
        "print(op)\n",
        "print(\"Tokens (str)      : {}\".format([tokenizer.convert_ids_to_tokens(s) for s in op['input_ids'].tolist()[0]]))\n",
        "print(\"Tokens (int)      : {}\".format(op['input_ids'].tolist()[0]))\n",
        "print(\"Tokens (attn_mask): {}\\n\".format(op['attention_mask'].tolist()[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[    5,   168,   459,   397,   707,   473,  1823, 17709,     6]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "Tokens (str)      : ['[CLS]', '▁나', '는', '▁오늘', '▁학교', '에', '▁간다', '.', '[SEP]']\n",
            "Tokens (int)      : [5, 168, 459, 397, 707, 473, 1823, 17709, 6]\n",
            "Tokens (attn_mask): [1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN_gSqSrJQAL"
      },
      "source": [
        "# KoQuAD1.0 데이터 Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271,
          "referenced_widgets": [
            "f95af5dd0ad2453c98844469c6c0369d",
            "542aa6f5c3e94009be307fd9cc7e6408",
            "fe0d8c696f9644d598eebfef52978517",
            "ed9acc2394a14d05b009c6fe46c8ce3c",
            "fba25d63e9614f9691577e548467074b",
            "46119ae8b33d402e9e14ef2983559f06",
            "f7cad090fe6541429cca37a3fadf7244",
            "04c12ccfffd3400b8fbf27416086fd7a",
            "abe036311be64734a8a4ff3520ed1854",
            "307485b366e54d0db305e87bb054b875",
            "8f8d6354c09e4e3fb10cef30eefcfe95",
            "d6264dc5cacc4b7e9d2da02b794fca00",
            "934a430476b04c5f90d52098b79b85ac",
            "eccf84dec1d54300b1f4aa3c0b0283b9",
            "11788a079e1a4e659eba67cad37f9db7",
            "af5a7aa73df44e7da5ae5cb6600bb7a5",
            "fcb63762f109495eaec5e986ed8d47ee",
            "ae03d406f7d24d1eafc0f102ac36f620",
            "a726d0ea30a54a0b8195512090d8f2fc",
            "3960871bf6c44e1992c4546f600000a2",
            "ceb1e77743594ebeafac45a38f7211b1",
            "1325cc98dec64864b369ffe20967c5a3",
            "e9495c01bbf64fe093166943b9d2c946",
            "30c8b8b8d0da421f952a0e02f86808da",
            "8aca210eb4db4d1096ffe5b182dfbd75",
            "b96072972cd74d1da530ce7a51f7cd44",
            "ec292c4d93b24cc78698ab42e3efc529",
            "23a84e0e5c3441b0b870b1b5834c7603",
            "800baa665d7141c2a8a87e6f208205da",
            "3e304dbe27844b1682f74db353ca6be7",
            "60aca6b057e641d9a0784417fbc3b50f",
            "293a0adf173b40dcbf3aca1166da112c",
            "1b72efa4d6994de4a3c939d2a5696833",
            "712dd6241561459cad7fca9a391cae16",
            "2a9d5509cec043aa8265f9126d538226",
            "f80926be439d4d9c8acf5571a04d5f40",
            "43c0ae258df441d087a1af3d7cb48833",
            "5d6b3726ae2544f0bd6a57bf25574ae1",
            "0dc553e839bd41409b47bc5205a8f0a4",
            "c9cae9a8928d40afbe94174c655ac834",
            "49180f796c004ca787dc81d8ef9acd35",
            "7c3bfdd325894a34b9b2f16083e7ba47",
            "29d2a17be6e14b45b5ce15bbe7b53cc3",
            "3582486f19584d139856c652ece67b7c",
            "e0a040fb522b45489f5a86028d462c85",
            "95fa74684d87493f85682675c818f882",
            "3eea9c3f59e144f593935c4c745cbcda",
            "194e4e272e0443c4ba2c4189d8d6baad"
          ]
        },
        "id": "GxHkhgjRJVFv",
        "outputId": "4be0d73f-cafd-43bb-f29b-5d27b1d05d87"
      },
      "source": [
        "from datasets import list_datasets, load_dataset, list_metrics, load_metric, load_from_disk\n",
        "\n",
        "squad_dataset = load_dataset('squad_kor_v1') "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f95af5dd0ad2453c98844469c6c0369d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1710.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abe036311be64734a8a4ff3520ed1854",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=962.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading and preparing dataset squad_kor_v1/squad_kor_v1 (download: 40.44 MiB, generated: 87.40 MiB, post-processed: Unknown size, total: 127.84 MiB) to /root/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/92f88eedc7d67b3f38389e8682eabe68caa450442cc4f7370a27873dbc045fe4...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcb63762f109495eaec5e986ed8d47ee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=7568316.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8aca210eb4db4d1096ffe5b182dfbd75",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=770480.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b72efa4d6994de4a3c939d2a5696833",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49180f796c004ca787dc81d8ef9acd35",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset squad_kor_v1 downloaded and prepared to /root/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/92f88eedc7d67b3f38389e8682eabe68caa450442cc4f7370a27873dbc045fe4. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqU8Q1p2JkJL",
        "outputId": "a637652e-64fb-4120-df4c-aa04233ae30b"
      },
      "source": [
        "%%time\n",
        "\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "squad_dataset_train = {}\n",
        "squad_dataset_train['id'] = []\n",
        "squad_dataset_train['title'] = []\n",
        "squad_dataset_train['context'] = []\n",
        "squad_dataset_train['question'] = []\n",
        "squad_dataset_train['answers'] = []\n",
        "\n",
        "\n",
        "for sdt in squad_dataset['train']:\n",
        "    if  len(sdt['answers']['answer_start']) > 0:\n",
        "        squad_dataset_train['id'].append(sdt['id'])\n",
        "        squad_dataset_train['title'].append(sdt['title'])\n",
        "        squad_dataset_train['context'].append(sdt['context'])\n",
        "        squad_dataset_train['question'].append(sdt['question'])\n",
        "        squad_dataset_train['answers'].append(sdt['answers'])\n",
        "\n",
        "dataset_train = Dataset.from_dict(squad_dataset_train)\n",
        "\n",
        "squad_dataset_val = {}\n",
        "squad_dataset_val['id'] = []\n",
        "squad_dataset_val['title'] = []\n",
        "squad_dataset_val['context'] = []\n",
        "squad_dataset_val['question'] = []\n",
        "squad_dataset_val['answers'] = []\n",
        "\n",
        "for sdt in squad_dataset['validation']:\n",
        "    if  len(sdt['answers']['answer_start']) > 0:\n",
        "        squad_dataset_val['id'].append(sdt['id'])\n",
        "        squad_dataset_val['title'].append(sdt['title'])\n",
        "        squad_dataset_val['context'].append(sdt['context'])\n",
        "        squad_dataset_val['question'].append(sdt['question'])\n",
        "        squad_dataset_val['answers'].append(sdt['answers'])\n",
        "\n",
        "dataset_val = Dataset.from_dict(squad_dataset_val)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.03 s, sys: 395 ms, total: 6.42 s\n",
            "Wall time: 6.15 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohLyW4TgJv1r",
        "outputId": "52f2ac12-7afc-40bc-e4d0-8d85e36f0909"
      },
      "source": [
        "%%time\n",
        "\n",
        "train_contexts = dataset_train['context']\n",
        "train_questions = dataset_train['question']\n",
        "train_answers = dataset_train['answers']\n",
        "\n",
        "val_contexts = dataset_val['context']\n",
        "val_questions = dataset_val['question']\n",
        "val_answers = dataset_val['answers']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.11 s, sys: 72.5 ms, total: 1.18 s\n",
            "Wall time: 1.18 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqvCK2x9J6TG"
      },
      "source": [
        "def add_end_idx(answers, contexts):\n",
        "    for answer, context in zip(answers, contexts):\n",
        "        try:\n",
        "        \n",
        "            gold_text = answer['text']\n",
        "            if isinstance(gold_text,list):\n",
        "                gold_text = gold_text[0]\n",
        "\n",
        "            start_idx = answer['answer_start']\n",
        "            if isinstance(start_idx,list):\n",
        "                start_idx = start_idx[0]\n",
        "\n",
        "            end_idx = start_idx + len(gold_text)\n",
        "\n",
        "            # sometimes squad answers are off by a character or two – fix this\n",
        "            if context[start_idx:end_idx] == gold_text:\n",
        "                answer['answer_end'] = [end_idx]\n",
        "            elif context[start_idx-1:end_idx-1] == gold_text:\n",
        "                answer['answer_start'] = [start_idx - 1]\n",
        "                answer['answer_end'] = [end_idx - 1]     # When the gold label is off by one character\n",
        "            elif context[start_idx-2:end_idx-2] == gold_text:\n",
        "                answer['answer_start'] = [start_idx - 2]\n",
        "                answer['answer_end'] = [end_idx - 2]     # When the gold label is off by two characters\n",
        "        except Exception as e:\n",
        "            pass\n",
        "            #print('context',context)\n",
        "            #print('gold_text',gold_text)\n",
        "\n",
        "\n",
        "add_end_idx(train_answers, train_contexts)\n",
        "add_end_idx(val_answers, val_contexts)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8hTx2G5J7jD"
      },
      "source": [
        "from transformers import AlbertTokenizerFast\n",
        "\n",
        "tokenizer = AlbertTokenizerFast.from_pretrained('/content/drive/MyDrive/Tokenizer_train/albert_tokenizer_model_special2/model')\n",
        "\n",
        "train_encodings = tokenizer(train_contexts, train_questions, max_length=512, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_contexts, val_questions, max_length=512, truncation=True, padding=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2631889UxcA"
      },
      "source": [
        "squad_dataset = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfWPKZFDKFPr"
      },
      "source": [
        "def add_token_positions(encodings, answers):\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    for i in range(len(answers)):\n",
        "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start'][0]))\n",
        "        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'][0] - 1))\n",
        "\n",
        "        # if start position is None, the answer passage has been truncated\n",
        "        if start_positions[-1] is None:\n",
        "            start_positions[-1] = tokenizer.model_max_length\n",
        "        if end_positions[-1] is None:\n",
        "            end_positions[-1] = tokenizer.model_max_length\n",
        "\n",
        "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "\n",
        "add_token_positions(train_encodings, train_answers)\n",
        "add_token_positions(val_encodings, val_answers)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p47o9_FNiqZG"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVuhMvRgKIBO"
      },
      "source": [
        "import torch\n",
        "\n",
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "    #def __getitem__(self, idx):\n",
        "    #    return {key: val[idx] for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = SquadDataset(train_encodings)\n",
        "val_dataset = SquadDataset(val_encodings)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4BQJiKzhHqq",
        "outputId": "5a5ddd3b-1d4f-4aff-9a4e-5475979db545"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6ja7OlvLLeW",
        "outputId": "8e007ef1-53a9-4cbf-b6e8-2303288c9a44"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW, AlbertForQuestionAnswering\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = AlbertForQuestionAnswering.from_pretrained('/content/drive/MyDrive/Tokenizer_train/albert-xlarge-kor')\n",
        "model.to(device)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "optim = AdamW(model.parameters(), lr=5e-5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of AlbertForQuestionAnswering were not initialized from the model checkpoint at /content/drive/MyDrive/Tokenizer_train/albert-xlarge-kor and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdTGtftBLPpI"
      },
      "source": [
        "# Print iterations progress\n",
        "class ProgressBar:\n",
        "\n",
        "  def __init__(self,total=20, prefix = '', suffix = '', decimals = 1, length = 20, fill = '█', printEnd = \"\\r\"):\n",
        "    self.total = total\n",
        "    self.prefix = prefix\n",
        "    self.suffix = suffix\n",
        "    self.decimals = decimals\n",
        "    self.length = length\n",
        "    self.fill = fill\n",
        "    self.printEnd = printEnd\n",
        "    self.ite = 0\n",
        "\n",
        "  def printProgress(self,iteration, text):\n",
        "      self.ite += iteration\n",
        "      percent = (\"{0:.\" + str(self.decimals) + \"f}\").format(100 * (self.ite / float(self.total)))\n",
        "\n",
        "      filledLength = int(self.length * self.ite // self.total)\n",
        "      bar = self.fill * filledLength + '-' * (self.length - filledLength)\n",
        "      print(f'\\r{self.prefix} |{bar}| {percent}% {self.suffix}  {text}', end=\"\", flush=True)\n",
        "      # Print New Line on Complete\n",
        "      if self.ite == self.total: \n",
        "          print()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "3ePbOGWILUjQ",
        "outputId": "906833d2-806d-4dcd-ca9d-485b8cfb0942"
      },
      "source": [
        "\n",
        "batch_count = len(train_loader)\n",
        "model.to(device)\n",
        "model.train()\n",
        "#loss_graph = []\n",
        "epochs = 1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    #seeding(1024+epoch)\n",
        "    pb = ProgressBar(total=batch_count,prefix='Epoch '+ str(epoch+1) + '/' + str(epochs))\n",
        "    current_batch = 0\n",
        "    for batch in train_loader:\n",
        "        current_batch+=1\n",
        "        #seeding(1024+epoch+current_batch)\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        #print('input_ids',len(input_ids))\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        #print('attention_mask',len(attention_mask))\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        #print('start_positions',len(start_positions))\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "        #print('end_positions',len(end_positions))\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        pb.printProgress(+1,'loss:' + str(loss))\n",
        "        #loss_graph.append(loss.item())\n",
        "    model.save_pretrained('/content/drive/MyDrive/korQuAD1.0/model')\n",
        "\n",
        "model.eval()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch 1/1 |--------------------| 0.0%   loss:tensor(6.2383, device='cuda:0', grad_fn=<DivBackward0>)"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-efaf00a7b8ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mend_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end_positions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print('end_positions',len(end_positions))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_positions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_positions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_positions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_positions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m         )\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m         )\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers_per_group\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgroup_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers_per_group\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             )\n\u001b[1;32m    469\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_group_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malbert_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malbert_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mattention_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         )\n\u001b[1;32m    390\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_layer_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1993\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/albert/modeling_albert.py\u001b[0m in \u001b[0;36mff_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mff_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mffn_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36mgelu_new\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mthe\u001b[0m \u001b[0mGaussian\u001b[0m \u001b[0mError\u001b[0m \u001b[0mLinear\u001b[0m \u001b[0mUnits\u001b[0m \u001b[0mpaper\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1606.08415\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.044715\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 15.78 GiB total capacity; 14.42 GiB already allocated; 6.75 MiB free; 14.48 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2kbBC4e_2Tm"
      },
      "source": [
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/drive/MyDrive/korQuAD1.0/model',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='/content/drive/MyDrive/korQuAD1.0/logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset             # evaluation dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCnkYdpoLeh1"
      },
      "source": [
        "model = AlbertForQuestionAnswering.from_pretrained('/content/drive/MyDrive/korQuAD1.0/model')\n",
        "#model = AlbertForQuestionAnswering.from_pretrained('/content/drive/MyDrive/Tokenizer_train/albert-kor-base')\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "examples = dataset_val\n",
        "\n",
        "def display_example(example):    \n",
        "    from pprint import pprint\n",
        "\n",
        "    #idx = qid_to_example_index[qid]\n",
        "    q = example['question']\n",
        "    c = example['context']\n",
        "    a = example['answers']['text']\n",
        "    \n",
        "    print(f'Example {example[\"id\"]} of {len(examples)}\\n---------------------')\n",
        "    print(f\"Q: {q}\\n\")\n",
        "    print(\"Context:\")\n",
        "    pprint(c)\n",
        "    print(f\"\\nTrue Answers:\\n{a}\")\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "def get_prediction(example,display=False):\n",
        "\n",
        "    if display:\n",
        "        display_example(example)\n",
        "    # given a question id (qas_id or qid), load the example, get the model outputs and generate an answer\n",
        "    question = example['question'] #examples[qid_to_example_index[qid]].question_text\n",
        "    context = example['context'] #examples[qid_to_example_index[qid]].context_text\n",
        "\n",
        "    #print(f\"Q: {question}\\n\")\n",
        "    #print(\"Context:\")\n",
        "    #pprint(context)\n",
        "\n",
        "    inputs = tokenizer.encode_plus(question, context, max_length=256,return_tensors='pt')\n",
        "\n",
        "    inputs.to(device)\n",
        "    \n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    #print(outputs)\n",
        "    #print(outputs)    \n",
        "    answer_start = torch.argmax(outputs[0])  # get the most likely beginning of answer with the argmax of the score\n",
        "    answer_end = torch.argmax(outputs[1]) + 1 \n",
        "\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
        "    if display:\n",
        "        print('')\n",
        "        print('Predict answer:',answer)\n",
        "    return answer\n",
        "\n",
        " # these functions are heavily influenced by the HF squad_metrics.py script\n",
        "def normalize_text(s):\n",
        "    \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
        "    import string, re\n",
        "\n",
        "    def remove_articles(text):\n",
        "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "        return re.sub(regex, \" \", text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return \" \".join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def compute_exact_match(prediction, truth):\n",
        "    return int(normalize_text(prediction) == normalize_text(truth))\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "    pred_tokens = normalize_text(prediction).split()\n",
        "    truth_tokens = normalize_text(truth).split()\n",
        "    \n",
        "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
        "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
        "        return int(pred_tokens == truth_tokens)\n",
        "    \n",
        "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "    \n",
        "    # if there are no common tokens then f1 = 0\n",
        "    if len(common_tokens) == 0:\n",
        "        return 0\n",
        "    \n",
        "    prec = len(common_tokens) / len(pred_tokens)\n",
        "    rec = len(common_tokens) / len(truth_tokens)\n",
        "    \n",
        "    return 2 * (prec * rec) / (prec + rec)\n",
        "\n",
        "def get_gold_answers(example):\n",
        "    \"\"\"helper function that retrieves all possible true answers from a squad2.0 example\"\"\"\n",
        "    \n",
        "    gold_answers = example['answers']['text'] #[answer[\"text\"] for answer in example['answers'] if answer[\"text\"]]\n",
        "\n",
        "    # if gold_answers doesn't exist it's because this is a negative example - \n",
        "    # the only correct answer is an empty string\n",
        "    if not gold_answers:\n",
        "        gold_answers = [\"\"]\n",
        "        \n",
        "    return gold_answers\n",
        "\n",
        "def evaluate_example(example,display=False):\n",
        "    gold_answers = get_gold_answers(example)\n",
        "    prediction = get_prediction(example)\n",
        "    em_score = max((compute_exact_match(prediction, answer)) for answer in gold_answers)\n",
        "    f1_score = max((compute_f1(prediction, answer)) for answer in gold_answers)\n",
        "    if display:\n",
        "        print(f\"Question: {example['question']}\")\n",
        "        print(f\"Prediction: {prediction}\")\n",
        "        print(f\"True Answers: {gold_answers}\")\n",
        "        print(f\"EM: {em_score} \\t F1: {f1_score}\")\n",
        "    return em_score,f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYMzvq5-LlXC",
        "outputId": "bd9ed673-83a3-41d6-b2ee-79f10d605a34"
      },
      "source": [
        "em,f1 = evaluate_example(examples[0],display=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question: 임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배 된 날은?\n",
            "Prediction: 1989년 2월 15일\n",
            "True Answers: ['1989년 2월 15일']\n",
            "EM: 1 \t F1: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF_CW4-uLob1",
        "outputId": "0533ba4a-8056-4548-94b2-07d3c2bbbf3b"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "ems = []\n",
        "f1s = []\n",
        "pb = ProgressBar(total=len(examples),prefix='Evaluate... ')\n",
        "for example in examples:\n",
        "    em,f1 = evaluate_example(example)\n",
        "    ems.append(em)\n",
        "    f1s.append(f1)\n",
        "    pb.printProgress(+1,'EM:' + str(em) + '  F1:' + str(f1))\n",
        "print('EM:',np.mean(ems))\n",
        "print('F1:',np.mean(f1s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate...  |████████████████████| 100.0%   EM:0  F1:0.5\n",
            "EM: 0.4664011084170419\n",
            "F1: 0.5565387760024785\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}